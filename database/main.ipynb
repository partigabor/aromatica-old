{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encyclopaedia Aromatica pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import date, datetime, timedelta\n",
    "from py_markdown_table.markdown_table import markdown_table\n",
    "\n",
    "# pip install babelnet\n",
    "\n",
    "from plotly.io import write_image, write_json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import geopandas as gpd\n",
    "\n",
    "from palette import *\n",
    "from scripts.unsplash import *\n",
    "from scripts.pexels import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = \"data/\"\n",
    "path_out_tex = \"output/tex/\"\n",
    "path_out_md = \"output/md/\"\n",
    "path_out_html = \"output/html/\"\n",
    "path_out_json = \"output/json/\"\n",
    "path_out_png = \"output/png/\"\n",
    "path_out_pdf = \"output/pdf/\"\n",
    "path_downloaded_photos = \"output/photos/\"\n",
    "\n",
    "website_md = \"../content/items/\"\n",
    "website_json = \"../static/plotly/\"\n",
    "website_photos = \"../static/images/photos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    " \n",
    "# def fetch_wikidata(params):\n",
    "#     url = 'https://www.wikidata.org/w/api.php'\n",
    "#     try:\n",
    "#         return requests.get(url, params=params)\n",
    "#     except:\n",
    "#         return 'There was and error'\n",
    "\n",
    "# # What text to search for\n",
    "# query = 'Elettaria cardamomum'\n",
    " \n",
    "# # Which parameters to use\n",
    "# params = {\n",
    "#         'action': 'wbsearchentities',\n",
    "#         'format': 'json',\n",
    "#         'search': query,\n",
    "#         'language': 'en'\n",
    "#     }\n",
    " \n",
    "# # Fetch API\n",
    "# data = fetch_wikidata(params)\n",
    " \n",
    "# #show response as JSON\n",
    "# data = data.json()\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "锡兰肉桂 錫蘭肉桂\n",
      "xílánròugùi\n",
      "sek3 laan4 juk6 gwai3\n",
      "ground dried berrylike fruit of a West Indian allspice tree; suggesting combined flavors of cinnamon and nutmeg and cloves\n",
      "[Synset('allspice.n.01'), Synset('allspice.n.02'), Synset('allspice.n.03')]\n",
      "['pepe_della_Giamaica', 'pimento']\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# List all files in a folder, including subfolders\n",
    "def list_files(dir):                                                                                                  \n",
    "    r = []                                                                                                            \n",
    "    subdirs = [x[0] for x in os.walk(dir)]                                                                            \n",
    "    for subdir in subdirs:                                                                                            \n",
    "        files = os.walk(subdir).__next__()[2]                                                                             \n",
    "        if (len(files) > 0):                                                                                          \n",
    "            for file in files:                                                                                        \n",
    "                r.append(os.path.join(subdir, file))                                                                         \n",
    "    return r\n",
    "\n",
    "################################################################################\n",
    "# Move or copy files between folders\n",
    "import os, shutil, pathlib, fnmatch\n",
    "\n",
    "def move_dir(src: str, dst: str, pattern: str = '*'):\n",
    "    if not os.path.isdir(dst):\n",
    "        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n",
    "    for f in fnmatch.filter(os.listdir(src), pattern):\n",
    "        shutil.move(os.path.join(src, f), os.path.join(dst, f))\n",
    "\n",
    "def copy_dir(src: str, dst: str, pattern: str = '*'):\n",
    "    if not os.path.isdir(dst):\n",
    "        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n",
    "    for f in fnmatch.filter(os.listdir(src), pattern):\n",
    "        shutil.copy(os.path.join(src, f), os.path.join(dst, f))\n",
    "\n",
    "################################################################################\n",
    "# Roman numerals from Arabic numerals\n",
    "def roman(num: int) -> str:\n",
    "\n",
    "    chlist = \"VXLCDM\"\n",
    "    rev = [int(ch) for ch in reversed(str(num))]\n",
    "    chlist = [\"I\"] + [chlist[i % len(chlist)] + \"\\u0304\" * (i // len(chlist))\n",
    "                    for i in range(0, len(rev) * 2)]\n",
    "    def period(p: int, ten: str, five: str, one: str) -> str:\n",
    "        if p == 9:\n",
    "            return one + ten\n",
    "        elif p >= 5:\n",
    "            return five + one * (p - 5)\n",
    "        elif p == 4:\n",
    "            return one + five\n",
    "        else:\n",
    "            return one * p\n",
    "    return \"\".join(reversed([period(rev[i], chlist[i * 2 + 2], chlist[i * 2 + 1], chlist[i * 2])\n",
    "                            for i in range(0, len(rev))]))\n",
    "def century(year):\n",
    "    return (year) // 100 + 1 \n",
    "\n",
    "# print(roman(17)) to call function\n",
    "\n",
    "################################################################################\n",
    "# Get coordinates for a place\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"MyApp\")\n",
    "\n",
    "def coordinates(place):\n",
    "    location = geolocator.geocode(place)\n",
    "    lat, lon = location.latitude, location.longitude\n",
    "    coord = [lat, lon]\n",
    "    return coord\n",
    "# print(coordinates(\"Hong Kong\"))\n",
    "\n",
    "# Generate geo-coordinates from location in a df\n",
    "def generate_coordinates(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['lat']) and pd.notna(row['lon']):\n",
    "            location = geolocator.geocode(row['location'])\n",
    "            df.at[index, 'lat_gen'] = location.latitude\n",
    "            df.at[index, 'lon_gen'] = location.longitude\n",
    "    return df\n",
    "\n",
    "# Generate coordinates based on native regions\n",
    "def generate_centroid_coordinates(df):\n",
    "    # Load the geographic data (shapefile or GeoJSON) # https://github.com/tdwg/wgsrpd\n",
    "    gdf = gpd.read_file(\"data\\\\resources\\\\geo\\\\level3.geojson\")\n",
    "    for index, row in df.iterrows():\n",
    "        native_distribution = row['native regions'].split(', ')\n",
    "        # Filter data for native distribution from gdf dataframe's LEVEL3_NAM column\n",
    "        native_data = gdf[gdf['LEVEL3_NAM'].isin(native_distribution)].copy() \n",
    "        # Calculate centroid data\n",
    "        native_centroid = native_data.centroid\n",
    "        df.at[index, 'lat_gen'] = native_centroid.y.iloc[0]\n",
    "        df.at[index, 'lon_gen'] = native_centroid.x.iloc[0]\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "# Convert Chinese Text to Simplified if needed\n",
    "import opencc\n",
    "tcsc = opencc.OpenCC('t2s.json')\n",
    "sctc = opencc.OpenCC('s2t.json')\n",
    "print(tcsc.convert('錫蘭肉桂'), sctc.convert('锡兰肉桂'))\n",
    "\n",
    "# ################################################################################\n",
    "# Transcribe Chinese into pinyin or jyutping\n",
    "import pinyin\n",
    "import jyutping\n",
    "py = pinyin.get('錫蘭肉桂')\n",
    "jp = jyutping.get('錫蘭肉桂')\n",
    "print(py)\n",
    "print(' '.join(jp))\n",
    "\n",
    "################################################################################\n",
    "# Hex to RGBA\n",
    "from PIL import ImageColor as ic\n",
    "def hex_to_rgba(hex):\n",
    "    rgb = str(ic.getrgb(hex))\n",
    "    rgba = re.sub('\\)', ', 1.0)', rgb)\n",
    "    return rgba\n",
    "\n",
    "# hex_to_rgba(nord0)\n",
    "\n",
    "# ################################################################################\n",
    "# # Convert PDFs\n",
    "# from pdf2image import convert_from_path\n",
    "\n",
    "# def convert_pdf_to_png(file):\n",
    "#     name = str(file)\n",
    "#     name = re.sub(\".*(?=/)\", \"\", name)\n",
    "#     name = re.sub(\"\\..*\", \"\", name)\n",
    "#     pages = convert_from_path(file, 0)\n",
    "#     for page in pages:\n",
    "#         page.save(path + name + \".png\", 'PNG')\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# Regex cheatsheet\n",
    "\n",
    "# (?!) - negative lookahead\n",
    "# (?=) - positive lookahead\n",
    "# (?<=) - positive lookbehind\n",
    "# (?<!) - negative lookbehind\n",
    "\n",
    "# (?>) - atomic group\n",
    "\n",
    "# ################################################################################\n",
    "# Wordnets using the Open Multilingual WordNet (https://omwn.org/omw1.html) # 100%: cmn, fin, hrv\n",
    "# wn_langs = ['als', 'arb', 'bul', 'cat', 'cmn', 'dan', 'ell', 'eng', 'eus', 'fin', 'fra', 'glg', 'heb', 'hrv', 'ind', 'isl', 'ita', 'ita_iwn', 'jpn', 'lit', 'nld', 'nno', 'nob', 'pol', 'por', 'slv', 'spa', 'swe', 'tha', 'zsm'] # 100%: cmn, fin, hrv\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"omw-1.4\")\n",
    "# nltk.download(\"extended_omw\") # if you want the wiktionary data\n",
    "\n",
    "wn_langs = ['fra'] # 'eng', 'arb', 'cmn', \n",
    "print(wn.synset('allspice.n.03').definition())\n",
    "print(wn.synsets('allspice', pos='n'))\n",
    "print(wn.synset('allspice.n.03').lemma_names('ita'))\n",
    "\n",
    "def wn_define(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['wn']):\n",
    "            wn_definition = wn.synset(row['wn']).definition()\n",
    "            df.at[index, f\"wn_def\"] = wn_definition\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "# Translations\n",
    "\n",
    "def wn_translate(df, lan):\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['wn']):\n",
    "            translated_list = wn.synset(row['wn']).lemma_names(lan)\n",
    "            translated = \", \".join(str(x) for x in translated_list)\n",
    "            translated = re.sub(\"_\", \" \", translated)\n",
    "            df.at[index, f\"translated_wn_{lan}\"] = translated\n",
    "    return df\n",
    "\n",
    "################################################################################\n",
    "# Translate with DeepL, use any translator you like, in this example GoogleTranslator\n",
    "# ChatGptTranslator, MicrosoftTranslator, DeeplTranslator; need API\n",
    "# https://developers.google.com/admin-sdk/directory/v1/languages\n",
    "# dl_languages = {'afrikaans': 'af', 'albanian': 'sq', 'amharic': 'am', 'arabic': 'ar', 'armenian': 'hy', 'assamese': 'as', 'aymara': 'ay', 'azerbaijani': 'az', 'bambara': 'bm', 'basque': 'eu', 'belarusian': 'be', 'bengali': 'bn', 'bhojpuri': 'bho', 'bosnian': 'bs', 'bulgarian': 'bg', 'catalan': 'ca', 'cebuano': 'ceb', 'chichewa': 'ny', 'chinese (simplified)': 'zh-CN', 'chinese (traditional)': 'zh-TW', 'corsican': 'co', 'croatian': 'hr', 'czech': 'cs', 'danish': 'da', 'dhivehi': 'dv', 'dogri': 'doi', 'dutch': 'nl', 'english': 'en', 'esperanto': 'eo', 'estonian': 'et', 'ewe': 'ee', 'filipino': 'tl', 'finnish': 'fi', 'french': 'fr', 'frisian': 'fy', 'galician': 'gl', 'georgian': 'ka', 'german': 'de', 'greek': 'el', 'guarani': 'gn', 'gujarati': 'gu', 'haitian creole': 'ht', 'hausa': 'ha', 'hawaiian': 'haw', 'hebrew': 'iw', 'hindi': 'hi', 'hmong': 'hmn', 'hungarian': 'hu', 'icelandic': 'is', 'igbo': 'ig', 'ilocano': 'ilo', 'indonesian': 'id', 'irish': 'ga', 'italian': 'it', 'japanese': 'ja', 'javanese': 'jw', 'kannada': 'kn', 'kazakh': 'kk', 'khmer': 'km', 'kinyarwanda': 'rw', 'konkani': 'gom', 'korean': 'ko', 'krio': 'kri', 'kurdish (kurmanji)': 'ku', 'kurdish (sorani)': 'ckb', 'kyrgyz': 'ky', 'lao': 'lo', 'latin': 'la', 'latvian': 'lv', 'lingala': 'ln', 'lithuanian': 'lt', 'luganda': 'lg', 'luxembourgish': 'lb', 'macedonian': 'mk', 'maithili': 'mai', 'malagasy': 'mg', 'malay': 'ms', 'malayalam': 'ml', 'maltese': 'mt', 'maori': 'mi', 'marathi': 'mr', 'meiteilon (manipuri)': 'mni-Mtei', 'mizo': 'lus', 'mongolian': 'mn', 'myanmar': 'my', 'nepali': 'ne', 'norwegian': 'no', 'odia (oriya)': 'or', 'oromo': 'om', 'pashto': 'ps', 'persian': 'fa', 'polish': 'pl', 'portuguese': 'pt', 'punjabi': 'pa', 'quechua': 'qu', 'romanian': 'ro', 'russian': 'ru', 'samoan': 'sm', 'sanskrit': 'sa', 'scots gaelic': 'gd', 'sepedi': 'nso', 'serbian': 'sr', 'sesotho': 'st', 'shona': 'sn', 'sindhi': 'sd', 'sinhala': 'si', 'slovak': 'sk', 'slovenian': 'sl', 'somali': 'so', 'spanish': 'es', 'sundanese': 'su', 'swahili': 'sw', 'swedish': 'sv', 'tajik': 'tg', 'tamil': 'ta', 'tatar': 'tt', 'telugu': 'te', 'thai': 'th', 'tigrinya': 'ti', 'tsonga': 'ts', 'turkish': 'tr', 'turkmen': 'tk', 'twi': 'ak', 'ukrainian': 'uk', 'urdu': 'ur', 'uyghur': 'ug', 'uzbek': 'uz', 'vietnamese': 'vi', 'welsh': 'cy', 'xhosa': 'xh', 'yiddish': 'yi', 'yoruba': 'yo', 'zulu': 'zu'}\n",
    "\n",
    "# from deep_translator import GoogleTranslator as dl\n",
    "# translated = dl(source='en', target='hu').translate(\"allspice\") # api_key=openai\n",
    "# print(translated)\n",
    "\n",
    "# dl_languages = {'french': 'fr'} # 'hungarian': 'hu', 'english': 'en', 'arabic': 'ar', 'chinese': 'zh-TW',\n",
    "# dl_language_list = list(dl_languages.values())\n",
    "\n",
    "# def translate(df, lang):\n",
    "#     for index, row in df.iterrows():\n",
    "#         if pd.notna(row['English']):\n",
    "#             translated = dl(source='en', target=lang).translate(row['English'])\n",
    "#             df.at[index, f\"translated_dl_{lang}\"] = translated\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 spices in total.\n",
      "['Sichuan pepper', 'allspice', 'anise', 'asafoetida', 'caraway', 'cardamom', 'cassia', 'chile', 'cinnamon', 'clove', 'coriander', 'cumin', 'dill', 'fennel', 'fenugreek', 'ginger', 'long pepper', 'mace', 'nutmeg', 'pepper', 'saffron', 'star anise', 'turmeric', 'vanilla']\n",
      "['allspice', 'anise', 'asafoetida', 'caraway', 'cardamom', 'cassia', 'chile', 'cinnamon', 'clove', 'coriander', 'cumin', 'dill', 'fennel', 'fenugreek', 'ginger', 'long_pepper', 'mace', 'nutmeg', 'pepper', 'saffron', 'sichuan_pepper', 'star_anise', 'turmeric', 'vanilla']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>include</th>\n",
       "      <th>values</th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>group</th>\n",
       "      <th>...</th>\n",
       "      <th>Hi translit</th>\n",
       "      <th>Hi literal</th>\n",
       "      <th>Hi alt</th>\n",
       "      <th>Indonesian</th>\n",
       "      <th>Malay</th>\n",
       "      <th>Persian</th>\n",
       "      <th>key</th>\n",
       "      <th>url</th>\n",
       "      <th>no. of native regions</th>\n",
       "      <th>no. of introduced regions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>81</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>gandhadravya?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>allspice</td>\n",
       "      <td>https://partigabor.github.io/aromatica/items/a...</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>72</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>moti saunf</td>\n",
       "      <td>fat fennel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adas manis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>بادیان رومی، انیسون</td>\n",
       "      <td>anise</td>\n",
       "      <td>https://partigabor.github.io/aromatica/items/a...</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>72</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>hīng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asafoetida</td>\n",
       "      <td>https://partigabor.github.io/aromatica/items/a...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>61</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jintan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caraway</td>\n",
       "      <td>https://partigabor.github.io/aromatica/items/c...</td>\n",
       "      <td>67</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>82</td>\n",
       "      <td>S</td>\n",
       "      <td>Z</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cardamoms</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cardamom</td>\n",
       "      <td>https://partigabor.github.io/aromatica/items/c...</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  include  values id  1  2  3    4    5    6      group  ...    Hi translit  \\\n",
       "0      in      81  S  M  P  D  NaN  1.0  1.0        NaN  ...  gandhadravya?   \n",
       "1      in      72  S  A  P  A  NaN  1.0  1.0        NaN  ...     moti saunf   \n",
       "2      in      72  S  A  F  F  NaN  1.0  1.0        NaN  ...           hīng   \n",
       "3      in      61  S  A  C  C  NaN  1.0  1.0        NaN  ...            NaN   \n",
       "4      in      82  S  Z  E  C  NaN  1.0  1.0  cardamoms  ...            NaN   \n",
       "\n",
       "   Hi literal Hi alt   Indonesian   Malay              Persian         key  \\\n",
       "0         NaN     NaN         NaN     NaN                  NaN    allspice   \n",
       "1  fat fennel     NaN  adas manis     NaN  بادیان رومی، انیسون       anise   \n",
       "2         NaN     NaN         NaN     NaN                  NaN  asafoetida   \n",
       "3         NaN     NaN         NaN  jintan                  NaN     caraway   \n",
       "4         NaN     NaN         NaN     NaN                  NaN    cardamom   \n",
       "\n",
       "                                                 url no. of native regions  \\\n",
       "0  https://partigabor.github.io/aromatica/items/a...                    13   \n",
       "1  https://partigabor.github.io/aromatica/items/a...                     4   \n",
       "2  https://partigabor.github.io/aromatica/items/a...                     8   \n",
       "3  https://partigabor.github.io/aromatica/items/c...                    67   \n",
       "4  https://partigabor.github.io/aromatica/items/c...                     2   \n",
       "\n",
       "  no. of introduced regions  \n",
       "0                      11.0  \n",
       "1                      42.0  \n",
       "2                       NaN  \n",
       "3                      57.0  \n",
       "4                       7.0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and store content of an excel file \n",
    "df = pd.read_excel(path_in+\"spices.xlsx\")\n",
    "\n",
    "# Write the dataframe object into csv file\n",
    "df.to_csv (path_in+\"spices.csv\", index = None, header=True)\n",
    "\n",
    "# Load in dataset of spices as a dataframe\n",
    "df = pd.read_csv(path_in+'spices.csv', header=[0], delimiter=',', encoding=\"utf-8\")\n",
    "\n",
    "# Select ones to include\n",
    "df = df.loc[(df['include'] == \"in\")]\n",
    "\n",
    "# Info\n",
    "list_of_items = df['item'].tolist()\n",
    "list_of_items.sort()\n",
    "print(len(list_of_items), \"spices in total.\")\n",
    "print(list_of_items)\n",
    "\n",
    "# Add keys based on item, make lowercase and replace spaces with underscores\n",
    "df['key'] = df['item'].str.lower().str.replace(\" \", \"_\")\n",
    "list_of_keys = df['key'].tolist()\n",
    "print(list_of_keys)\n",
    "\n",
    "# Add links\n",
    "df['url'] = \"https://partigabor.github.io/aromatica/items/\" + df['item'].str.replace(\" \", \"_\")\n",
    "\n",
    "# Add counts of distribution\n",
    "df['no. of native regions'] = df['native regions'].str.count(',') + 1\n",
    "df['no. of introduced regions'] = df['introduced regions'].str.count(',') + 1\n",
    "\n",
    "# Location coordinates\n",
    "# generate_coordinates(df) # Generate geo-coordinates from location\n",
    "# generate_centroid_coordinates(df) # Generate geo-coordinates by finding the centroid of the native regions\n",
    "\n",
    "# Get a definition from wordnet\n",
    "# wn_define(df)\n",
    "\n",
    "# # Translate the names to other languages using OMW\n",
    "# for lang in wn_langs:\n",
    "#     wn_translate(df, lang)\n",
    "\n",
    "# # Machine ranslate the names to other languages\n",
    "# for lang in dl_language_list:\n",
    "#     translate(df, lang)\n",
    "\n",
    "# # Check\n",
    "# df_translations = df.filter(regex='translated')\n",
    "# df_translations\n",
    "\n",
    "# Assign\n",
    "df_items = df.copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting categories (spices, herbs, incense)\n",
    "# df_spices = df.loc[(df['id'] == \"S\")]\n",
    "# print(df_spices.shape[0])\n",
    "# df_herbs = df.loc[(df['id'] == \"H\")]\n",
    "# print(df_herbs.shape[0])\n",
    "# df_incense = df.loc[(df['id'] == \"I\")]\n",
    "# print(df_incense.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download images from Unsplash and pexels to be curated later\n",
    "# item = \"black pepper\"\n",
    "# dashed_key = re.sub(\" \", \"-\", item)\n",
    "# unsplash_downloader(dashed_key, path_downloaded_photos)\n",
    "# pexels_downloader(item, path_downloaded_photos)\n",
    "\n",
    "# # # Move images to the right folder\n",
    "# # move_dir(path_downloaded_photos + dashed_key, website_photos + dashed_key, \"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               key  img_count  \\\n",
      "0         allspice          0   \n",
      "1            anise          0   \n",
      "2       asafoetida          0   \n",
      "3          caraway          0   \n",
      "4         cardamom          0   \n",
      "5           cassia          0   \n",
      "6            chile          0   \n",
      "7         cinnamon          0   \n",
      "8            clove          0   \n",
      "9        coriander          0   \n",
      "10           cumin          1   \n",
      "11            dill          0   \n",
      "12          fennel          0   \n",
      "13       fenugreek          0   \n",
      "14          ginger          0   \n",
      "15     long_pepper          0   \n",
      "16            mace          0   \n",
      "17          nutmeg          0   \n",
      "18          pepper          6   \n",
      "19         saffron          0   \n",
      "20  sichuan_pepper          0   \n",
      "21      star_anise          0   \n",
      "22        turmeric          1   \n",
      "23         vanilla          0   \n",
      "\n",
      "                                           img_source  \\\n",
      "0                                                       \n",
      "1                                                       \n",
      "2                                                       \n",
      "3                                                       \n",
      "4                                                       \n",
      "5                                                       \n",
      "6                                                       \n",
      "7                                                       \n",
      "8                                                       \n",
      "9                                                       \n",
      "10                                           Unsplash   \n",
      "11                                                      \n",
      "12                                                      \n",
      "13                                                      \n",
      "14                                                      \n",
      "15                                                      \n",
      "16                                                      \n",
      "17                                                      \n",
      "18  Unsplash, Unsplash, Unsplash, Unsplash, Unspla...   \n",
      "19                                                      \n",
      "20                                                      \n",
      "21                                                      \n",
      "22                                           Unsplash   \n",
      "23                                                      \n",
      "\n",
      "                   img_extension  \n",
      "0                                 \n",
      "1                                 \n",
      "2                                 \n",
      "3                                 \n",
      "4                                 \n",
      "5                                 \n",
      "6                                 \n",
      "7                                 \n",
      "8                                 \n",
      "9                                 \n",
      "10                           jpg  \n",
      "11                                \n",
      "12                                \n",
      "13                                \n",
      "14                                \n",
      "15                                \n",
      "16                                \n",
      "17                                \n",
      "18  jpg, jpg, jpg, jpg, jpg, jpg  \n",
      "19                                \n",
      "20                                \n",
      "21                                \n",
      "22                           jpg  \n",
      "23                                \n"
     ]
    }
   ],
   "source": [
    "# Define the relative folder path\n",
    "folder_path = '../static/images/photos'\n",
    "\n",
    "# List of keys\n",
    "list_of_keys.sort()\n",
    "\n",
    "# Initialize item_info dictionary\n",
    "item_info = {}  # Dictionary to store item information\n",
    "\n",
    "# Initialize item counts, extensions, file names, and sources to empty lists for each item\n",
    "for item in list_of_keys:\n",
    "    item_info[item] = {'count': 0, 'extensions': [], 'file_names': [], 'sources': []}\n",
    "\n",
    "# Iterate through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if os.path.isfile(os.path.join(folder_path, filename)):\n",
    "        # Extract the item name, extension, file name, and source from the file name\n",
    "        item_name = filename.split('-')[0]\n",
    "        extension = filename.split('.')[-1]\n",
    "        file_name = filename\n",
    "        source = filename.split('-')[2] if len(filename.split('-')) > 2 else \"\"\n",
    "        # Remove the file extension from the source\n",
    "        source = source.split('.')[0]\n",
    "        \n",
    "        # Check if the item name is in the list_of_items\n",
    "        if item_name in list_of_keys:\n",
    "            item_info[item_name]['count'] += 1\n",
    "            item_info[item_name]['extensions'].append(extension)\n",
    "            item_info[item_name]['file_names'].append(file_name)\n",
    "            item_info[item_name]['sources'].append(source)\n",
    "\n",
    "# Create a Pandas DataFrame from the item_info dictionary\n",
    "data = {'key': [], 'count': [], 'source': [], 'extension': []}\n",
    "for item, info in item_info.items():\n",
    "    data['key'].append(item)\n",
    "    data['count'].append(info['count'])\n",
    "    data['source'].append(', '.join(info['sources']))\n",
    "    data['extension'].append(', '.join(info['extensions']))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill in missing items with 0 image counts and empty sources, extensions\n",
    "for item in list_of_keys:\n",
    "    if item not in df['key'].values:\n",
    "        df = df.append({'key': item, 'count': 0, 'source': '', 'extension': ''}, ignore_index=True)\n",
    "\n",
    "# Reorder the DataFrame with columns 'item', 'count', 'source', 'extension'\n",
    "df = df[['key', 'count', 'source', 'extension']]\n",
    "\n",
    "# Sort the DataFrame by 'item'\n",
    "df = df.sort_values(by='key')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns={'count': 'img_count', 'source': 'img_source', 'extension': 'img_extension'}, inplace=True)\n",
    "\n",
    "# Save\n",
    "df_images = df.copy()\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df)\n",
    "\n",
    "# Merge the two dataframes\n",
    "df_items = pd.merge(df_items, df_images, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and store content of an excel file \n",
    "df = pd.read_excel(path_in+\"names.xlsx\")\n",
    "\n",
    "# Write the dataframe object into csv file\n",
    "df.to_csv (path_in+\"names.csv\", index = None, header=True)\n",
    "\n",
    "# Load in dataset of names\n",
    "df = pd.read_csv(path_in+'names.csv', header =[0], delimiter=',', encoding=\"utf-8\")\n",
    "\n",
    "# Select ones to include\n",
    "df = df.loc[df['include'] == 'yes'] # include ones to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 names in total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gparti\\AppData\\Local\\Temp\\ipykernel_16288\\819533664.py:2: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change NaN to empty string\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Info\n",
    "print(df.shape[0], \"names in total.\")\n",
    "\n",
    "# Assign\n",
    "df_names = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etymologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 words in total\n",
      "['tester', 'allspice', 'fulful ifranji', 'duoxiangguo', 'pimento', 'anise', 'anisun', 'huiqin', 'asafoetida', 'hing', 'hiltit', 'anjudan', 'awei', 'xingqu', 'caraway', 'karawiya', 'geluzi', 'cardamom', 'amomum', 'hal', 'qaqulla', 'doukou', 'cassia', 'salikha', 'rougui', 'cinnamon', 'darsini', 'qirfa', 'chile', 'fulful harr', 'lajiao', 'paprika', 'clove', 'qaranful', 'dingxiang', 'coriander', 'kuzbura', 'yansui', 'husui', 'cumin', 'kammun', 'ziran', 'dill', 'shibitt', 'shiluo', 'fennel', 'shamar', 'huixiang', 'fenugreek', 'hulba', 'huluba', 'ginger', 'zanjabil', 'jiang', 'long pepper', 'darfilfil', 'biba', 'mace', 'basbas', 'roudoukoupi', 'nutmeg', 'jawz al-tib', 'roudoukou', 'pepper', 'fulful', 'hujiao', 'bors', 'saffron', 'zafaran', 'fanhonghua', 'Sichuan pepper', 'fagara', 'fulful sitshuwan', 'huajiao', 'star anise', 'yansun najmi', 'bajiaohuixiang', 'badian', 'turmeric', 'kurkum', 'jianghuang', 'vanilla', 'faniliya', 'xiangcao']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gparti\\anaconda3\\envs\\work\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning:\n",
      "\n",
      "'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and store content of an excel file \n",
    "read_file = pd.read_excel(path_in+\"etymologies.xlsx\")\n",
    "\n",
    "# Write the dataframe object into csv file\n",
    "read_file.to_csv (path_in+\"etymologies.csv\", index = None, header=True)\n",
    "\n",
    "# Load in dataset\n",
    "df_etymologies=pd.read_csv(path_in+'etymologies.csv', header =[0], delimiter=',', encoding=\"utf-8\")\n",
    "\n",
    "# Split the dataset wherever an empty row is found\n",
    "df_list_with_na = np.split(df_etymologies, df_etymologies[df_etymologies.isnull().all(1)].index)\n",
    "\n",
    "# Drop NAs and reset the index\n",
    "df_list = []\n",
    "for df in df_list_with_na:\n",
    "  df = df.dropna(how='all')\n",
    "  df.reset_index(inplace=True, drop=True)\n",
    "  df_list.append(df)\n",
    "\n",
    "# Automatically extract IDs from the dataset\n",
    "list_of_etymologies = []\n",
    "for df in df_list:\n",
    "  # print(df['item'].iloc[0])\n",
    "  df = df.dropna(how='all')\n",
    "  df.reset_index(drop=True)\n",
    "  item = str(df['item'].iloc[0])\n",
    "  list_of_etymologies.append(item)\n",
    "\n",
    "# Print the number if IDs and what are they\n",
    "length = len(df_list)\n",
    "print(length, \"words in total\")\n",
    "print(list_of_etymologies)\n",
    "\n",
    "#Create a defaultdict of spice-word etymologies\n",
    "etymologies=defaultdict(list)\n",
    "for i in range(length):\n",
    "  etymologies[list_of_etymologies[i]]=df_list[i]\n",
    "\n",
    "# Testing\n",
    "# print(etymologies['saffron'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etymology box for LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = \"tester\"\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# # The following code will create an etymology box environment for the key, to be used in LaTeX\n",
    "# print(\"Started the generation of '\" + key + \"' as etymbox...\")\n",
    "\n",
    "# df_local = etymologies[key]\n",
    "# # df_local.fillna('', inplace=True)\n",
    "\n",
    "# # # Skipping those marked\n",
    "# df_local = df_local[df_local['boxskip'] != 'yes']\n",
    "# df_local.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# # # Replace empty cells with NaNs\n",
    "# # df_local.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "# # df_local.replace(r'^nan$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "# # Create content and sources stage by stage\n",
    "# content = \"\"\n",
    "# source = \"\"\n",
    "# sources = \"\"\n",
    "# source_list = []\n",
    "# nl = \"\\n\"\n",
    "\n",
    "# for index, row in df_local.iterrows():\n",
    "#   stage = \"< \"\n",
    "#   if pd.notna(row['complex']): # complex relationships\n",
    "#     row['complex'] = re.sub(\"and from\", \"+\", row['complex'])\n",
    "#     stage += row['complex'] + \" \"\n",
    "#   if pd.notna(row['language']): # language\n",
    "#     stage += \"\\\\textbf{\" + row['language'] + \"} \"\n",
    "#   if pd.notna(row['script']): # script\n",
    "#     script = \"{\" + row['script'] + \"} \"\n",
    "#     if row['language'] == 'Chinese':\n",
    "#       script = \"\\\\tc{\" + row['script'] + \"} \"\n",
    "#     stage += script\n",
    "#   if pd.notna(row['term']): # term\n",
    "#     stage += \"\\\\textit{\" + row['term'] + \"} \"\n",
    "#   if pd.notna(row['IPA']): # IPA\n",
    "#     stage += row['IPA'] + \" \"\n",
    "#   if pd.notna(row['meaning']): # meaning\n",
    "#     stage += \"`\" + row['meaning'] + \"' \"\n",
    "#   if pd.notna(row['literal']): # literal meaning\n",
    "#     stage += \"[\" + row['literal'] + \"] \"\n",
    "#   stage = re.sub(' $', '', stage)\n",
    "#   stage += \", \"\n",
    "#   if pd.notna(row['explanation']): # explanation\n",
    "#     stage += row['explanation'] + \" \"\n",
    "#   if pd.notna(row['remark']): # remark\n",
    "#     stage += \"(\" + row['remark'] + \") \"\n",
    "#   stage = re.sub(',? ?$', '', stage)\n",
    "\n",
    "#   if pd.notna(row['date']): # dates\n",
    "#     stage += \", \"\n",
    "#     row['date'] = re.sub('a(?=\\d)', 'a. ', row['date'])\n",
    "#     row['date'] = re.sub('c(?=\\d)', 'ca. ', row['date'])\n",
    "#     if re.match('^-\\d\\d?$', row['date']): # if is a century BC\n",
    "#       row['date'] = re.sub(\"-\", \"\", row['date'])\n",
    "#       date = \"\\\\nth{\" + row['date'] + \"} c. \\BC{}\" # ARAB NUMERALS\n",
    "#       # date = \" \" + roman(row['date']) + \" \\BC{}\" # ROMAN NUMERALS\n",
    "#     elif re.match('^\\d\\d?$', row['date']): # if is a century AD\n",
    "#       date = \"\\\\nth{\" + row['date'] + \"} c. \\AD{}\" # ARAB NUMERALS\n",
    "#       # date = \" \" + roman(row['date']) + \" \\AD{}\" # ROMAN NUMERALS\n",
    "#     else:\n",
    "#       date = row['date'] + \" \" # if it's a year\n",
    "#     stage += date\n",
    "#     stage = re.sub(',? ?$', '', stage)\n",
    "#   if pd.notna(row['cognates']): # cognates\n",
    "#     stage += \"; cf. cognates \" + row['cognates'] + \" \"\n",
    "#   if pd.notna(row['derivates']): # cognates\n",
    "#     if pd.notna(row['cognates']):\n",
    "#       stage = re.sub(' $', '', stage)\n",
    "#       stage += \"; \" + row['derivates'] + \" \"\n",
    "#     else:\n",
    "#       stage = re.sub(' $', '', stage)\n",
    "#       stage += \"; cf. \" + row['derivates'] + \" \"\n",
    "#   stage = re.sub(',? ?$', '', stage)\n",
    "#   # stage = re.sub('cf\\..*?(cf\\.)', '', stage)\n",
    "\n",
    "# # Final touches\n",
    "#   if row['doubt'] == 'yes':\n",
    "#     stage = re.sub(r'<', '<\\\\\\\\textss{?}', stage) # ???\n",
    "#   if row['complex'] == '+':\n",
    "#     stage = re.sub('<', '', stage)\n",
    "#   if row['complex'] == 'or from':\n",
    "#     stage = re.sub('<', '', stage)\n",
    "#   content += stage + nl\n",
    "\n",
    "# # Sources\n",
    "#   source=\"\"\n",
    "#   if pd.notna(row['source zotero']):\n",
    "#     source = row['source zotero']\n",
    "#     print(\"1\",source)\n",
    "#     if '{' in source:\n",
    "#       source = \"s\" + row['source zotero'].lower()\n",
    "#       print(source)\n",
    "#     else:\n",
    "#       source = \"{\" + row['source zotero'].lower() + \"}\"\n",
    "#       print(source)\n",
    "#     if pd.notna(row['source page']):\n",
    "#       source = \"[\" + str(row['source page']) + \"]{\" + row['source zotero'].lower() + \"}\"\n",
    "#       print(\"4\",source)\n",
    "#       if row['source page'].isalpha() == True:\n",
    "#         source = \"[s.v. \" + str(row['source page']) + \"]{\" + row['source zotero'].lower() + \"}\"\n",
    "#         print(\"5\",source)\n",
    "#     source = \"\\\\textcite\" + source\n",
    "#   print(source)\n",
    "#   source_list.append(source)\n",
    "\n",
    "# # clear duplicates from sources:\n",
    "# print(\"SL1: \", source_list)\n",
    "# # source_set = sorted(set(source_list), key=source_list.index)\n",
    "# source_set = set(source_list)\n",
    "# print(\"SS2: \", source_set)\n",
    "# source_list2 = list(source_set)\n",
    "# print(\"S3: \", source_list2)\n",
    "# sources_unduplicated = '; '.join(source_list2)\n",
    "# print(\"S4: \", sources_unduplicated)\n",
    "# # test for duplicates\n",
    "# newlist = [] # empty list to hold unique elements from the list\n",
    "# duplist = [] # empty list to hold the duplicate elements from the list\n",
    "# for i in source_list:\n",
    "#     if i not in newlist:\n",
    "#         newlist.append(i)\n",
    "#     else:\n",
    "#         duplist.append(i) # this method catches the first duplicate entries, and appends them to the list\n",
    "\n",
    "# # The next stage is to print the duplicate entries, and the unique entries\n",
    "# print(\"List of duplicates\", duplist)\n",
    "# print(\"Unique Item List\", newlist) \n",
    "# if len(duplist) > 0:\n",
    "#   # print(\"UNDUPL\")\n",
    "#   sources = sources_unduplicated\n",
    "# else:\n",
    "#   # print(\"ORI\")\n",
    "#   sources =  '; '.join(source_list)\n",
    "# # print(\"S5: \", sources)\n",
    "\n",
    "# sources =  '; '.join(source_list)\n",
    "\n",
    "# # Cleaning\n",
    "# sources = re.sub(\"; $\", \"\", sources)\n",
    "# sources = re.sub(\"^; \", \"\", sources)\n",
    "# sources = re.sub(\"(; )+\", \"; \", sources)\n",
    "# sources = \"\\\\footnote{\" + sources + \"}\\n\"\n",
    "\n",
    "# content = re.sub(\"\\n$\", \"\", content)\n",
    "# content = re.sub(r\"^< \", \"\", content) # delete the first <\n",
    "# content = re.sub(r\"\\n,\", \",\", content)\n",
    "# content = re.sub(r\" nan \", \" \", content)\n",
    "# content = re.sub(\"(<\\.\\n?)+$\", \"\", content)\n",
    "\n",
    "# content += sources\n",
    "\n",
    "# env_begin = r\"\\begin{etymology}\" + \"\\label{ety:\" + df_local['item'].iloc[0] + \"}\" + nl \n",
    "# env_end = r\"\\end{etymology}\"\n",
    "\n",
    "# box = env_begin + content + env_end\n",
    "# box = re.sub(r\"\\u200e\", \"\", box) #removes right to left mark\n",
    "\n",
    "# # Save the spicebox as a standalone tex file\n",
    "\n",
    "# filename = re.sub(\" \", \"_\", key)\n",
    "# filename = filename.lower()\n",
    "# f = open(path_out_tex + \"{}.tex\".format(\"etymbox_\" + filename), \"w\", encoding='utf-8')\n",
    "# f.write(box)\n",
    "# f.close()\n",
    "# print(\"Etymology-box '\" + str(key) + \"' as a tex file was created.\")\n",
    "# box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def etymbox(key):\n",
    "  \n",
    "#   # The following code will create a etymology box environment for the key, to be used in LaTeX\n",
    "#   print(\"Started the generation of '\" + key + \"' as etymbox...\")\n",
    "\n",
    "#   df_local = etymologies[key]\n",
    "#   # df_local.fillna('', inplace=True)\n",
    "\n",
    "#   # # Skipping those marked\n",
    "#   df_local = df_local[df_local['boxskip'] != 'yes']\n",
    "#   df_local.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#   # # Replace empty cells with NaNs\n",
    "#   # df_local.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "#   # df_local.replace(r'^nan$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "#   # Create content and sources stage by stage\n",
    "#   content = \"\"\n",
    "#   source = \"\"\n",
    "#   sources = \"\"\n",
    "#   source_list = []\n",
    "#   nl = \"\\n\"\n",
    "\n",
    "#   for index, row in df_local.iterrows():\n",
    "#     stage = \"< \"\n",
    "#     if pd.notna(row['complex']): # complex relationships\n",
    "#       row['complex'] = re.sub(\"and from\", \"+\", row['complex'])\n",
    "#       stage += row['complex'] + \" \"\n",
    "#     if pd.notna(row['language']): # language\n",
    "#       stage += \"\\\\textbf{\" + row['language'] + \"} \"\n",
    "#     if pd.notna(row['script']): # script\n",
    "#       script = \"{\" + row['script'] + \"} \"\n",
    "#       if row['language'] == 'Chinese':\n",
    "#         script = \"\\\\tc{\" + row['script'] + \"} \"\n",
    "#       stage += script\n",
    "#     if pd.notna(row['term']): # term\n",
    "#       stage += \"\\\\textit{\" + row['term'] + \"} \"\n",
    "#     if pd.notna(row['IPA']): # IPA\n",
    "#       stage += row['IPA'] + \" \"\n",
    "#     if pd.notna(row['meaning']): # meaning\n",
    "#       stage += \"`\" + row['meaning'] + \"' \"\n",
    "#     if pd.notna(row['literal']): # literal meaning\n",
    "#       stage += \"[\" + row['literal'] + \"] \"\n",
    "#     stage = re.sub(' $', '', stage)\n",
    "#     stage += \", \"\n",
    "#     if pd.notna(row['explanation']): # explanation\n",
    "#       stage += row['explanation'] + \" \"\n",
    "#     if pd.notna(row['remark']): # remark\n",
    "#       stage += \"(\" + row['remark'] + \") \"\n",
    "#     stage = re.sub(',? ?$', '', stage)\n",
    "\n",
    "#     if pd.notna(row['date']): # dates\n",
    "#       stage += \", \"\n",
    "#       row['date'] = re.sub('a(?=\\d)', 'a. ', row['date'])\n",
    "#       row['date'] = re.sub('c(?=\\d)', 'ca. ', row['date'])\n",
    "#       if re.match('^-\\d\\d?$', row['date']): # if is a century BC\n",
    "#         row['date'] = re.sub(\"-\", \"\", row['date'])\n",
    "#         date = \"\\\\nth{\" + row['date'] + \"} c. \\BC{}\" # ARAB NUMERALS\n",
    "#         # date = \" \" + roman(row['date']) + \" \\BC{}\" # ROMAN NUMERALS\n",
    "#       elif re.match('^\\d\\d?$', row['date']): # if is a century AD\n",
    "#         date = \"\\\\nth{\" + row['date'] + \"} c. \\AD{}\" # ARAB NUMERALS\n",
    "#         # date = \" \" + roman(row['date']) + \" \\AD{}\" # ROMAN NUMERALS\n",
    "#       else:\n",
    "#         date = row['date'] + \" \" # if it's a year\n",
    "#       stage += date\n",
    "#       stage = re.sub(',? ?$', '', stage)\n",
    "#     if pd.notna(row['cognates']): # cognates\n",
    "#       stage += \"; cf. cognates \" + row['cognates'] + \" \"\n",
    "#     if pd.notna(row['derivates']): # cognates\n",
    "#       if pd.notna(row['cognates']):\n",
    "#         stage = re.sub(' $', '', stage)\n",
    "#         stage += \"; \" + row['derivates'] + \" \"\n",
    "#       else:\n",
    "#         stage = re.sub(' $', '', stage)\n",
    "#         stage += \"; cf. \" + row['derivates'] + \" \"\n",
    "#     stage = re.sub(',? ?$', '', stage)\n",
    "#     # stage = re.sub('cf\\..*?(cf\\.)', '', stage)\n",
    "\n",
    "#   # Final touches\n",
    "#     if row['doubt'] == 'yes':\n",
    "#       stage = re.sub(r'<', '<\\\\\\\\textss{?}', stage) # ???\n",
    "#     if row['complex'] == '+':\n",
    "#       stage = re.sub('<', '', stage)\n",
    "#     if row['complex'] == 'or from':\n",
    "#       stage = re.sub('<', '', stage)\n",
    "#     content += stage + nl\n",
    "\n",
    "#   # Sources\n",
    "#     source=\"\"\n",
    "#     if pd.notna(row['source zotero']):\n",
    "#       source = row['source zotero']\n",
    "#       # print(source)\n",
    "#       if '{' in source:\n",
    "#         source = \"s\" + row['source zotero'].lower()\n",
    "#         # print(source)\n",
    "#       else:\n",
    "#         source = \"{\" + row['source zotero'].lower() + \"}\"\n",
    "#         # print(source)\n",
    "#       if pd.notna(row['source page']):\n",
    "#         source = \"[\" + str(row['source page']) + \"]{\" + row['source zotero'].lower() + \"}\"\n",
    "#         # print(source)\n",
    "#         if row['source page'].isalpha() == True:\n",
    "#           source = \"[s.v. \" + str(row['source page']) + \"]{\" + row['source zotero'].lower() + \"}\"\n",
    "#           # print(source)\n",
    "#       source = \"\\\\textcite\" + source\n",
    "#     # print(source)\n",
    "#     source_list.append(source)\n",
    "\n",
    "#   # clear duplicates from sources:\n",
    "#   # print(\"SL1: \", source_list)\n",
    "#   # source_set = sorted(set(source_list), key=source_list.index)\n",
    "#   source_set = set(source_list)\n",
    "#   # print(\"SS2: \", source_set)\n",
    "#   source_list2 = list(source_set)\n",
    "#   # print(\"S3: \", source_list2)\n",
    "#   sources_unduplicated = '; '.join(source_list2)\n",
    "#   # print(\"S4: \", sources_unduplicated)\n",
    "#   # test for duplicates\n",
    "#   newlist = [] # empty list to hold unique elements from the list\n",
    "#   duplist = [] # empty list to hold the duplicate elements from the list\n",
    "#   for i in source_list:\n",
    "#       if i not in newlist:\n",
    "#           newlist.append(i)\n",
    "#       else:\n",
    "#           duplist.append(i) # this method catches the first duplicate entries, and appends them to the list\n",
    "#   # The next stage is to print the duplicate entries, and the unique entries\n",
    "#   # print(\"List of duplicates\", duplist)\n",
    "#   # print(\"Unique Item List\", newlist) \n",
    "#   if len(duplist) > 0:\n",
    "#     # print(\"UNDUPL\")\n",
    "#     sources = sources_unduplicated\n",
    "#   else:\n",
    "#     # print(\"ORI\")\n",
    "#     sources =  '; '.join(source_list)\n",
    "#   # print(\"S5: \", sources)\n",
    "\n",
    "#   sources =  '; '.join(source_list)\n",
    "\n",
    "#   # Cleaning\n",
    "#   sources = re.sub(\"; $\", \"\", sources)\n",
    "#   sources = re.sub(\"^; \", \"\", sources)\n",
    "#   sources = re.sub(\"(; )+\", \"; \", sources)\n",
    "#   sources = \"\\\\footnote{\" + sources + \"}\\n\"\n",
    "\n",
    "#   content = re.sub(\"\\n$\", \"\", content)\n",
    "#   content = re.sub(r\"^< \", \"\", content) # delete the first <\n",
    "#   content = re.sub(r\"\\n,\", \",\", content)\n",
    "#   content = re.sub(r\" nan \", \" \", content)\n",
    "#   content = re.sub(\"(<\\.\\n?)+$\", \"\", content)\n",
    "\n",
    "#   content += sources\n",
    "\n",
    "#   env_begin = r\"\\begin{etymology}\" + \"\\label{ety:\" + df_local['item'].iloc[0] + \"}\" + nl \n",
    "#   env_end = r\"\\end{etymology}\"\n",
    "\n",
    "#   box = env_begin + content + env_end\n",
    "#   box = re.sub(r\"\\u200e\", \"\", box) #removes right to left mark\n",
    "\n",
    "#   # Save the spicebox as a standalone tex file\n",
    "#   filename = re.sub(\" \", \"_\", key)\n",
    "#   filename = filename.lower()\n",
    "#   f = open(path_out_tex + \"{}.tex\".format(\"etymbox_\" + filename), \"w\", encoding='utf-8')  \n",
    "#   f.write(box)\n",
    "#   f.close()\n",
    "#   print(\"Etymology-box '\" + str(key) + \"' as a tex file was created.\")\n",
    "\n",
    "#   return box\n",
    "\n",
    "# etymbox(\"tester\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etymology box for Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started the generation of 'tester' as etymbox...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'**Language A** тест *test* /tɛst/ \\'meaning1\\' [literal1], explanation1 (remark1); cf. cognates cognates1; derivates derivates1\\n< **Language B** тестер *tester* /ˈtɛstə/ \\'meaning2\\' [literal2], explanation2, AD 12 c.; cf. cognates cognates2\\n< **Language C** тестинг *testing* /ˈtɛstɪŋ/ \\'meaning3\\' [literal3] (remark3), 9 c. BC; cf. derivates derivates3\\n< **Language D** тесте *teste* /ˈaltə/ \\'meaning4\\' [literal4], explanation4 (remark4); cf. cognates cognates4; derivates derivates4\\n {{< cite \"oed;wehr_dictionary_1976;wehr_dictionary_1976;liddell_greekenglish_1940;wehr_dictionary_1976;lewis_latin_1879;liddell_greekenglish_1940\" \"1;2-3;4;5;6;;7\" >}}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def etymbox(key):\n",
    "\n",
    "  # The following code will create a etymology box environment for the key, to be used in Markdown\n",
    "  print(\"Started the generation of '\" + key + \"' as etymbox...\")\n",
    "\n",
    "  # Select word\n",
    "  df_local = etymologies[key]\n",
    "  # df_local.fillna('', inplace=True)\n",
    "\n",
    "  # Skipping those marked\n",
    "  df_local = df_local[df_local['skip'] != 'yes']\n",
    "  df_local.reset_index(inplace=True, drop=True)\n",
    "\n",
    "  # # Replace empty cells with NaNs\n",
    "  # df_local.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "  # df_local.replace(r'^nan$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "  # Initialize\n",
    "  content = \"\"\n",
    "  sources = \"\"\n",
    "  source_pages = \"\"\n",
    "\n",
    "  # Iterate through a word's etymology dataframe (stage by stage = row by row)\n",
    "  for index, row in df_local.iterrows():\n",
    "    # Initialize stage, add an '<' if its not the first stage\n",
    "    if index == 0:\n",
    "      stage = \"\"\n",
    "    else:\n",
    "      stage = \"< \"\n",
    "    # If there are complex relations, add them (e.g., partly, and, or)\n",
    "    if pd.notna(row['complex']):\n",
    "      stage += row['complex'] + \" \"\n",
    "    # Add language (in bold)\n",
    "    if pd.notna(row['language']):\n",
    "      stage += \"**\" + row['language'] + \"** \"\n",
    "    # Add the term with native script (if exists)\n",
    "    if pd.notna(row['script']):\n",
    "      stage += row['script'] + \" \"\n",
    "    # Add the term with transcription (in italics)\n",
    "    if pd.notna(row['term']):\n",
    "      stage += \"*\" + row['term'] + \"* \"\n",
    "    # Add /IPA/\n",
    "    if pd.notna(row['IPA']):\n",
    "      stage += \"/\" + row['IPA'] + \"/ \"\n",
    "    # Add 'meaning', gloss\n",
    "    if pd.notna(row['meaning']):\n",
    "      stage += \"'\" + row['meaning'] + \"' \"\n",
    "    # Add the [literal meaning] if there is one\n",
    "    if pd.notna(row['literal']):\n",
    "      stage += \"[\" + row['literal'] + \"] \"\n",
    "    # Clear ending\n",
    "    stage = re.sub(' $', '', stage)\n",
    "    # Add explanation\n",
    "    if pd.notna(row['explanation']):\n",
    "      stage += \", \" + row['explanation'] + \" \"\n",
    "    # Add (remark)\n",
    "    if pd.notna(row['remark']):\n",
    "      stage += \" (\" + row['remark'] + \") \"\n",
    "    # Clear ending\n",
    "    stage = re.sub(\" +\", \" \", stage)\n",
    "    stage = re.sub(\",? ?$\", \"\", stage)\n",
    "\n",
    "    # Add date, if there is a date\n",
    "    if pd.notna(row['date']):\n",
    "      # If it's a year\n",
    "      date = row['date']\n",
    "\n",
    "    # Add century if there is no date\n",
    "    if pd.notna(row['century']) and pd.isna(row['date']):\n",
    "      \n",
    "      # If it's a century BC\n",
    "      if re.match('^-\\d\\d?\\??$', row['century']):\n",
    "        # Remove dash\n",
    "        row['century'] = re.sub(\"-\", \"\", row['century'])\n",
    "        # If there is question mark\n",
    "        if re.match('\\d\\?', row['century']):\n",
    "          # Remove the question mark\n",
    "          row['century'] = re.sub(\"\\?\", \"\", row['century'])\n",
    "          # Date BC\n",
    "          # date = roman(int(row['century'])) + \" BC?\" # ROMAN NUMERALS\n",
    "          date = row['century'] + \" c. BC?\" # ARAB NUMERALS\n",
    "        else:\n",
    "          # date = roman(int(row['century'])) + \" BC\" # ROMAN NUMERALS\n",
    "          date = row['century'] + \" c. BC\" # ARAB NUMERALS\n",
    "\n",
    "      # If it is a century AD\n",
    "      elif re.match('^\\d\\d?\\??$', row['century']):\n",
    "        # If there is question mark\n",
    "        if re.match('\\d\\?', row['century']):\n",
    "          # Remove the question mark\n",
    "          row['century'] = re.sub(\"\\?\", \"\", row['century'])\n",
    "          # Date AD\n",
    "          # date = \"AD \" + roman(int(row['century'])) + \"?\" # ROMAN NUMERALS\n",
    "          date = \"AD \" + row['century'] + \" c.\" # ARAB NUMERALS\n",
    "        else:\n",
    "          # date = \"AD \" + roman(int(row['century'])) # ROMAN NUMERALS\n",
    "          date = \"AD \" + row['century'] + \" c.\" # ARAB NUMERALS\n",
    "\n",
    "      # Add date to stage\n",
    "      stage += \", \" + date\n",
    "      \n",
    "    # Clear ending\n",
    "    stage = re.sub(',? ?$', '', stage)\n",
    "\n",
    "    # If both cognates and derivates\n",
    "    if pd.notna(row['cognates']) and pd.notna(row['derivates']):\n",
    "      stage += \"; cf. cognates \" + row['cognates'] + \"; derivates \" + row['derivates'] + \" \"\n",
    "    # If cognates only\n",
    "    if pd.notna(row['cognates']) and pd.isna(row['derivates']):\n",
    "      stage += \"; cf. cognates \" + row['cognates'] + \" \"\n",
    "    # If derivates only\n",
    "    if pd.notna(row['derivates']) and pd.isna(row['cognates']):\n",
    "      stage += \"; cf. derivates \" + row['derivates'] + \" \"\n",
    "    \n",
    "    # Clear ending\n",
    "    stage = re.sub(';?,? ?$', '', stage)\n",
    "\n",
    "    # If stage is doubtful, use '<?'\n",
    "    if row['doubt'] == 'yes':\n",
    "      stage = re.sub('<', '<\\?', stage)\n",
    "    # If stage is \"complex\", remove '<'\n",
    "    if pd.notna(row['complex']):\n",
    "      stage = re.sub('<', '', stage)\n",
    "\n",
    "    # # Sources (at each stage) A\n",
    "    # source = \"\"\n",
    "    # # If there is source (zotero), add\n",
    "    # if pd.notna(row['source']):\n",
    "    #   source = '\\\"' + row['source'] + '\\\"'\n",
    "    #   # If there is page, add\n",
    "    #   if pd.notna(row['source page']):\n",
    "    #     source = '\\\"' + str(row['source'].lower()) + '\\\" \\\"' + str(row['source page']) + '\\\"'\n",
    "    # # Add the Hugo shortcode syntax \n",
    "    # source = r' {{< cite ' + source + r' >}}'\n",
    "    # # Create content\n",
    "    # content += stage + source + \"\\n\"\n",
    "\n",
    "    # Sources (once in the end, removing duplicates) B\n",
    "    # If there is source (zotero), add\n",
    "    if pd.notna(row['source']):\n",
    "      sources += row['source'] + \";\"\n",
    "      # If there is page, add\n",
    "      if pd.notna(row['source page']):\n",
    "        source_pages += str(row['source page']) + \";\"\n",
    "      else:\n",
    "        source_pages += \";\"\n",
    "    # Create content\n",
    "    content += stage + \"\\n\"\n",
    "\n",
    "  # If using version B of sources\n",
    "  # Clean ending\n",
    "  sources = re.sub(';?$', '', sources)\n",
    "  source_pages = re.sub(';?$', '', source_pages)\n",
    "  # Add the Hugo-cite shortcode syntax \n",
    "  source = r' {{< cite \"' + sources + r'\" \"' + source_pages + r'\" >}}'\n",
    "  # Add source to content\n",
    "  content += source\n",
    "\n",
    "  # Cleaning\n",
    "  box = content\n",
    "  box = re.sub(r\"\\u200e\", \"\", box) # Removes right-to-left mark\n",
    "\n",
    "  # # Save the spicebox as a standalone markdown file (if ever needed)\n",
    "  # filename = re.sub(\" \", \"_\", key)\n",
    "  # filename = filename.lower()\n",
    "  # f = open(path_out_md + \"{}.md\".format(\"etymbox_\" + filename), \"w\", encoding='utf-8')  \n",
    "  # f.write(box)\n",
    "  # f.close()\n",
    "  # print(\"Etymology-box '\" + str(key) + \"' as a md file was created.\")\n",
    "\n",
    "  return box\n",
    "\n",
    "etymbox(\"tester\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started the generation of 'tester' as etymbox...\n",
      "Started the generation of 'allspice' as etymbox...\n",
      "Started the generation of 'fulful ifranji' as etymbox...\n",
      "Started the generation of 'duoxiangguo' as etymbox...\n",
      "Started the generation of 'pimento' as etymbox...\n",
      "Started the generation of 'anise' as etymbox...\n",
      "Started the generation of 'anisun' as etymbox...\n",
      "Started the generation of 'huiqin' as etymbox...\n",
      "Started the generation of 'asafoetida' as etymbox...\n",
      "Started the generation of 'hing' as etymbox...\n",
      "Started the generation of 'hiltit' as etymbox...\n",
      "Started the generation of 'anjudan' as etymbox...\n",
      "Started the generation of 'awei' as etymbox...\n",
      "Started the generation of 'xingqu' as etymbox...\n",
      "Started the generation of 'caraway' as etymbox...\n",
      "Started the generation of 'karawiya' as etymbox...\n",
      "Started the generation of 'geluzi' as etymbox...\n",
      "Started the generation of 'cardamom' as etymbox...\n",
      "Started the generation of 'amomum' as etymbox...\n",
      "Started the generation of 'hal' as etymbox...\n",
      "Started the generation of 'qaqulla' as etymbox...\n",
      "Started the generation of 'doukou' as etymbox...\n",
      "Started the generation of 'cassia' as etymbox...\n",
      "Started the generation of 'salikha' as etymbox...\n",
      "Started the generation of 'rougui' as etymbox...\n",
      "Started the generation of 'cinnamon' as etymbox...\n",
      "Started the generation of 'darsini' as etymbox...\n",
      "Started the generation of 'qirfa' as etymbox...\n",
      "Started the generation of 'chile' as etymbox...\n",
      "Started the generation of 'fulful harr' as etymbox...\n",
      "Started the generation of 'lajiao' as etymbox...\n",
      "Started the generation of 'paprika' as etymbox...\n",
      "Started the generation of 'clove' as etymbox...\n",
      "Started the generation of 'qaranful' as etymbox...\n",
      "Started the generation of 'dingxiang' as etymbox...\n",
      "Started the generation of 'coriander' as etymbox...\n",
      "Started the generation of 'kuzbura' as etymbox...\n",
      "Started the generation of 'yansui' as etymbox...\n",
      "Started the generation of 'husui' as etymbox...\n",
      "Started the generation of 'cumin' as etymbox...\n",
      "Started the generation of 'kammun' as etymbox...\n",
      "Started the generation of 'ziran' as etymbox...\n",
      "Started the generation of 'dill' as etymbox...\n",
      "Started the generation of 'shibitt' as etymbox...\n",
      "Started the generation of 'shiluo' as etymbox...\n",
      "Started the generation of 'fennel' as etymbox...\n",
      "Started the generation of 'shamar' as etymbox...\n",
      "Started the generation of 'huixiang' as etymbox...\n",
      "Started the generation of 'fenugreek' as etymbox...\n",
      "Started the generation of 'hulba' as etymbox...\n",
      "Started the generation of 'huluba' as etymbox...\n",
      "Started the generation of 'ginger' as etymbox...\n",
      "Started the generation of 'zanjabil' as etymbox...\n",
      "Started the generation of 'jiang' as etymbox...\n",
      "Started the generation of 'long pepper' as etymbox...\n",
      "Started the generation of 'darfilfil' as etymbox...\n",
      "Started the generation of 'biba' as etymbox...\n",
      "Started the generation of 'mace' as etymbox...\n",
      "Started the generation of 'basbas' as etymbox...\n",
      "Started the generation of 'roudoukoupi' as etymbox...\n",
      "Started the generation of 'nutmeg' as etymbox...\n",
      "Started the generation of 'jawz al-tib' as etymbox...\n",
      "Started the generation of 'roudoukou' as etymbox...\n",
      "Started the generation of 'pepper' as etymbox...\n",
      "Started the generation of 'fulful' as etymbox...\n",
      "Started the generation of 'hujiao' as etymbox...\n",
      "Started the generation of 'bors' as etymbox...\n",
      "Started the generation of 'saffron' as etymbox...\n",
      "Started the generation of 'zafaran' as etymbox...\n",
      "Started the generation of 'fanhonghua' as etymbox...\n",
      "Started the generation of 'Sichuan pepper' as etymbox...\n",
      "Started the generation of 'fagara' as etymbox...\n",
      "Started the generation of 'fulful sitshuwan' as etymbox...\n",
      "Started the generation of 'huajiao' as etymbox...\n",
      "Started the generation of 'star anise' as etymbox...\n",
      "Started the generation of 'yansun najmi' as etymbox...\n",
      "Started the generation of 'bajiaohuixiang' as etymbox...\n",
      "Started the generation of 'badian' as etymbox...\n",
      "Started the generation of 'turmeric' as etymbox...\n",
      "Started the generation of 'kurkum' as etymbox...\n",
      "Started the generation of 'jianghuang' as etymbox...\n",
      "Started the generation of 'vanilla' as etymbox...\n",
      "Started the generation of 'faniliya' as etymbox...\n",
      "Started the generation of 'xiangcao' as etymbox...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary of etymologies\n",
    "dictionary_of_etymologies = {}\n",
    "# Loop\n",
    "for key in list_of_etymologies:\n",
    "    box = (etymbox(key))\n",
    "    # box = r'{{% notice style=\"primary\" title=\"Pirates\" icon=\"skull-crossbones\" %}}' + \"\\n\" + text + \"\\n\" + r\"{{% /notice %}}\" + \"\\n\\n\"\n",
    "    dictionary_update = {key: box}\n",
    "    dictionary_of_etymologies.update(dictionary_update)\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**English** *allspice*, from *all* + *spice*; after the flavor profile that resembles the combined aroma of cloves, nutmeg, cinnamon, and black pepper\\n {{< cite \"oed\" \"allspice\" >}}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "dictionary_of_etymologies['allspice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Spice Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Photo by <a href=\"https://unsplash.com/@veruschkade?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Vera De</a> on <a href=\"https://unsplash.com/photos/red-and-brown-fur-on-gray-concrete-floor-hTE438DvDgg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spicepage(item):\n",
    "    '''\n",
    "    This cell generates web pages from the spice datasets and writes them out to markdown files.\n",
    "    '''\n",
    "\n",
    "    pd.options.mode.copy_on_write = True # to avoid SettingWithCopyWarning, https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas\n",
    "    \n",
    "    # Get dataframe of current item\n",
    "    print(\"Working on\", item)\n",
    "    df_local = df_items.loc[df_items['item'] == item]\n",
    "    \n",
    "    # Reset index\n",
    "    df_local.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Generate key\n",
    "    key = re.sub(\" \", \"_\", item).lower()\n",
    "    \n",
    "    # Description\n",
    "    description = df_local['description'][0]\n",
    "    description = description[0].upper() + description[1:]\n",
    "    aka = \", also known as \" + str(df_local['en alt'].iloc[0]) + \". \" if pd.notna(df_local['en alt'].iloc[0]) else \"\" # review\n",
    "    related = \", related to \" + str(df_local['related'].iloc[0]) + \". \" if pd.notna(df_local['related'].iloc[0]) else \"\"\n",
    "    see_also = \"See also \" + str(df_local['see also'].iloc[0]) + \". \" if pd.notna(df_local['see also'].iloc[0]) else \"\"\n",
    "    preamble_description = description + aka + related + see_also\n",
    "    page_description = \">\" + description + aka + related + see_also + \"\\n\\n\"\n",
    "    # if pd.notna(df_local['wn'].iloc[0]):\n",
    "    #     wn_definition = wn.synset(df_local['wn'][0]).definition()\n",
    "    #     wn_definition = wn_definition[0].upper() + wn_definition[1:]\n",
    "    #     description = description + \"\\n\\nAccording to WordNet: \" + wn_definition + \".\\n\\n\"\n",
    "\n",
    "    # Extract categories and tags and groups (which will be treated as tags)\n",
    "    category = df_local['category'][0]\n",
    "    category_list = category.split(\"; \") if \";\" in category else [f'{category}']\n",
    "    tag = df_local['tag'][0]\n",
    "    tag_list = tag.split(\";\") if \";\" in tag else [f'{tag}']\n",
    "    if pd.notna(df_local['group'][0]):\n",
    "        group = df_local['group'][0]\n",
    "        group_list = group.split(\";\") if \";\" in group else [f'{group}']\n",
    "    else:\n",
    "        group_list = []\n",
    "    tag_list = tag_list + group_list\n",
    "\n",
    "    # Assemble preamble\n",
    "    preamble = f'+++\\ntitle = \"{item.title()}\"\\nauthor = \"Gabor Parti\"\\ndate = \"{str(date.today())}\"\\ndescription = \"{preamble_description}\"\\nweight = 10\\n# draft = \"true\"\\n# hidden = \"true\"\\nplotly = true\\ncategories = {str(category_list)}\\ntags = {str(tag_list)}\\nbibFile = \"static/files/bibliography.json\"\\n+++\\n\\n'\n",
    "\n",
    "    ###########################\n",
    "    ######## The Spice ########\n",
    "    ###########################\n",
    "    \n",
    "    # Overview \n",
    "    overview_head = \"## Overview\\n\\n\"\n",
    "    # Merge species name\n",
    "    df_local['species name'] = \"*\" + df_local['species'] + \"* \" + df_local['species by']\n",
    "    # Set link\n",
    "    df_local['botanical database'] = \"[POWO](\" + df_local['powo'] + \")\"\n",
    "    # Prepare overview tables\n",
    "    df_overview = df_local[['species name', 'family', 'part used', 'macroarea', 'region of origin', 'cultivation', 'color', 'botanical database']]\n",
    "    # Transpose table\n",
    "    df_overview = df_overview.T\n",
    "    # Reset index\n",
    "    df_overview.reset_index(inplace=True)\n",
    "    # Rename columns\n",
    "    df_overview.columns = ['item', item]\n",
    "    # Prepare data to create markdown table\n",
    "    data = df_overview.to_dict(orient='records')\n",
    "    # Create markdown table\n",
    "    overview_mdt = markdown_table(data).set_params(row_sep = 'markdown', quote = False).get_markdown()\n",
    "    # Table\n",
    "    overview = overview_head + overview_mdt + \"\\n\\n\"\n",
    "    \n",
    "    # Intro\n",
    "    category = re.sub('; ', ' and ', category)\n",
    "    tag = re.sub('; ', ' and ', tag)\n",
    "    part = re.sub('; ', ' and ', df_local['part used'][0])\n",
    "    intro = description + \". \" + item.title() + \" (\" + str(df_local['species name'][0]) + \")\" + \" is a \" + tag + \" \" + category + \" from the *\" + str(df_local['family'][0]) + \"* family,[^powo] originating in the region(s) of \" + str(df_local['region of origin'][0]) + \"It is used for its \" + part + \", primarily for \" + str(df_local['major uses'][0]) + \". Its aroma is described as \" + str(df_local['taste/smell'][0]) + \", with a heat index of \" + str(df_local['heat'][0]) + \".[^ucla_medicinal_2002]\" + \"\\n\\n\"\n",
    "    \n",
    "    # Create references\n",
    "    references = \"[^powo]: POWO. (2022). Plants of the World Online (Botanical Database). Facilitated by the Royal Botanic Gardens, Kew. http://www.plantsoftheworldonline.org/\\n[^ucla_medicinal_2002]: Medicinal Spices Exhibit. (2002). UCLA Biomedical Library: History & Special Collections. https://unitproj.library.ucla.edu/biomed/spice/index.cfm?spicefilename=taste.txt&itemsuppress=yes&displayswitch=0\\n\\n\"\n",
    "    # references = \"\"\n",
    "    \n",
    "    # Photo (todo, make list of img ext and source now they are string)\n",
    "    # if df_local['img_count'][0] > 0:\n",
    "    #     img_src = re.sub(',.*', '', df_local['img_source'][0])\n",
    "    #     img_src = re.sub('_', ' ', img_src)\n",
    "        \n",
    "    #     photo = \"![\" + df_local['item'][0] + \"](/images/photos/\" + df_local['item'][0] + \"-1-\" + re.sub(',.*', '', df_local['img_source'][0]) + \".\" + re.sub(',.*', '', df_local['img_extension'][0]) + \"?width=14rem&classes=shadow\" + ' \"Photo: ' + img_src + '\")\\n\\n'\n",
    "    # else:\n",
    "    #     photo = \"\"\n",
    "    \n",
    "    # Illustration # &classes=shadow\n",
    "    if pd.notna(df_local['ill source'].iloc[0]):\n",
    "        illustration_alt = \"Illustration of \" + df_local['species'][0] + \" from \" + df_local['ill source'][0]\n",
    "        illustration = \"![\" + df_local['species name'][0] + '](/images/illustrations/' + key + '.png?width=40rem \"' + illustration_alt + '\")' + '\\n'\n",
    "        illustration_source = df_local['ill source'][0] + r\"{{< cite -\" + str(df_local['ill key'][0]) + r\" >}} \" + str(df_local['ill page'][0]) + r\".\"\n",
    "        illustration = illustration + \"\\n>Illustration of \" + df_local['species'][0] + \" from \" + illustration_source\n",
    "        if pd.notna(df_local['ill link'].iloc[0]):\n",
    "            illustration = illustration + \" [{{% icon image %}}](\" + df_local['ill link'].iloc[0] + \")\"\n",
    "    else:\n",
    "        illustration = \"\"\n",
    "    illustration = illustration + \"\\n\\n\"\n",
    "    \n",
    "    # Top display gallery\n",
    "    if len(list_files(f\"../static/images/photos/{key}\")) > 1:\n",
    "        display_gallery = '{{< load-photoswipe >}}\\n\\n{{< gallery dir=\"/images/photos/' + key + '\" hover-effect=\"slideup\" caption-effect=\"fade\" caption-position=\"none\" />}}' + \"\\n\\n\"\n",
    "    else:\n",
    "        display_gallery = \"\"\n",
    "        \n",
    "    # Gallery on the bottom of the page\n",
    "    if os.path.isdir(f\"../static/images/photos/{key}/gallery\"):\n",
    "        gallery =  '## Gallery\\n\\n{{< load-photoswipe >}}\\n\\n{{< gallery dir=\"/images/photos/' + key + '/gallery\" hover-effect=\"slideup\" caption-effect=\"fade\" />}}' + \"\\n\\n\"\n",
    "    else:\n",
    "        gallery = \"\"\n",
    "\n",
    "    # Quick names (predefined)\n",
    "    if pd.notna(df_local['English'][0]):\n",
    "        en = \"**English:** \" + df_local['English'][0] + \" · \"\n",
    "    else:\n",
    "        en = \"\"\n",
    "    if pd.notna(df_local['Hungarian'][0]):\n",
    "        hu = \"**Hungarian:** \" + df_local['Hungarian'][0] + \" · \"\n",
    "    else:\n",
    "        hu = \"\"\n",
    "    if pd.notna(df_local['Arabic'][0]):\n",
    "        ar = '**Arabic:** <span class=\"arabic-text\" dir=\"rtl\">' + df_local['Arabic'][0] + '</span>' + \" · \"\n",
    "    else:\n",
    "        ar = \"\"\n",
    "    if pd.notna(df_local['Chinese'][0]):\n",
    "        zh = '**Chinese:** <span class=\"chinese-text\">' + df_local['Chinese'][0] + '</span>' + \" · \"\n",
    "    else:\n",
    "        zh = \"\"\n",
    "    \n",
    "    quick_names = en + hu + ar + zh\n",
    "    \n",
    "    if pd.notna(df_local['French'][0]):\n",
    "        fr = \"**French:** \" + df_local['French'][0] + \". \"\n",
    "        quick_names += fr\n",
    "    # Translate here with WN, DL or GT\n",
    "    # elif pd.notna(df_local['translated_wn_fra'][0]):\n",
    "    #     fr = \"**French:** \" + str(df_local['translated_wn_fra'][0])\n",
    "    # elif pd.notna(df_local['translated_dl_fr'][0]):\n",
    "    #     fr = \"**French:** \" + str(df_local['translated_dl_fr'][0])\n",
    "    else:\n",
    "        quick_names = quick_names\n",
    "    \n",
    "    quick_names = '<p style=\"text-align:center;\">\\n\\n' + quick_names + '\\n\\n</p>\\n\\n'\n",
    "    \n",
    "    # df_quick_names = df_local[['English', 'Arabic', 'Chinese', 'Hungarian']] # 'French' \n",
    "    # # df_names = df_names.T\n",
    "    # # df_names.reset_index(inplace=True)\n",
    "    # # df_names.columns = ['language', 'name(s)']\n",
    "    # data = df_quick_names.to_dict(orient='records')\n",
    "    # quick_names_mdt = markdown_table(data).set_params(row_sep = 'markdown', quote = False).get_markdown()\n",
    "    # quick_names = quick_names_mdt + \"\\n\\n\"\n",
    "\n",
    "    # Distribution\n",
    "    distribution = \"## Distribution\\n\\n\"\n",
    "    distribution = distribution + r'{{< load-plotly >}}' + '\\n\\n' + r'{{< plotly json=\"/aromatica/plotly/distributions/dist_' + key + r'.json\" weight=\"600\" height=\"300\" >}}' + '\\n\\n'\n",
    "    distribution = distribution + \">Native and introduced habitats of \" + str(df_local['species name'][0]) + \"[^powo]\\n\\n\"\n",
    "    # Check if 'native regions' is not empty and not 'NA' before adding to the string\n",
    "    regions = \"\"\n",
    "    if pd.notna(df_local['native regions'][0]) and df_local['native regions'][0] != 'NA':\n",
    "        regions += \"**Native regions:** &ensp; &ensp; &ensp; \" + df_local['native regions'][0] + \"\\n\\n\"\n",
    "    # Check if 'introduced regions' is not empty and not 'NA' before adding to the string\n",
    "    if pd.notna(df_local['introduced regions'][0]) and df_local['introduced regions'][0] != 'NA':\n",
    "        regions += \"**Introduced regions:** \" + df_local['introduced regions'][0] + \"\\n\\n\"\n",
    "    distribution += '<p style=\"text-align:left;\">\\n\\n' + regions + '</p>\\n\\n'\n",
    "    \n",
    "    ##################################\n",
    "    ######## The Nomenclature ########\n",
    "    ##################################\n",
    "\n",
    "    # Dataframe of current item \n",
    "    df_names_local = df_names.loc[df_names['item'] == item]\n",
    "\n",
    "    # Reset index\n",
    "    df_names_local.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Names\n",
    "    # names_head = \"***\\n\\n## Nomenclature\\n\\n\"\n",
    "    # Heads\n",
    "    # names_head_en = \"### English\\n\\n\"\n",
    "    # names_head_ar = \"### Arabic\\n\\n\"\n",
    "    # names_head_zh = \"### Chinese\\n\\n\"\n",
    "    \n",
    "    # # Language by language\n",
    "    # language = \"English\"\n",
    "    # df = df_names_local.loc[df_names_local['language'] == language]\n",
    "    # df = df[['term', 'source human']]\n",
    "    # df = df.rename(columns={'source human': 'source'})\n",
    "    # data = df.to_dict(orient='records')\n",
    "    # names_mdt_en = markdown_table(data).set_params(row_sep = 'markdown', quote = False).get_markdown()\n",
    "\n",
    "    # language = \"Arabic\"\n",
    "    # df = df_names_local.loc[df_names_local['language'] == language]\n",
    "    # df = df[['script', 'term', 'literal', 'source human']]\n",
    "    # df = df.rename(columns={'source human': 'source'})\n",
    "    # data = df.to_dict(orient='records')\n",
    "    # names_mdt_ar = markdown_table(data).set_params(row_sep = 'markdown', quote = False).get_markdown()\n",
    "\n",
    "    # language = \"Chinese\"\n",
    "    # df = df_names_local.loc[df_names_local['language'] == language]\n",
    "    # df = df[['script', 'term', 'literal', 'source human']]\n",
    "    # df = df.rename(columns={'source human': 'source'})\n",
    "    # data = df.to_dict(orient='records')\n",
    "    # names_mdt_zh = markdown_table(data).set_params(row_sep = 'markdown', quote = False).get_markdown()\n",
    "    # names = names_head + names_head_en + names_mdt_en + \"\\n\\n\" + names_head_ar + names_mdt_ar + \"\\n\\n\" + names_head_zh + names_mdt_zh + \"\\n\\n\"\n",
    "    names = \"\"\n",
    "\n",
    "    ################################\n",
    "    ####### The Etymologies #######\n",
    "    ################################\n",
    "\n",
    "    # wordlist = df_local['etymologies'][0].split(\"; \")\n",
    "    # etymologies = \"\"\n",
    "    # for word in wordlist:\n",
    "    #     etymologies += dictionary_of_etymologies[word]\n",
    "    # etymologies = \"## Etymologies\\n\\n\" + etymologies\n",
    "    etymologies = \"\"\n",
    "\n",
    "    # Plotly file\n",
    "    # jsons = \"\"\n",
    "    # key_ = re.sub(\" \", \"_\", item)\n",
    "    # jsons = r'{{< load-plotly >}}' + '\\n' + r'{{< plotly json=\"/plotly/diffusion_name_' + key_ + r'.json\" height=\"300px\" >}}' + '\\n\\n'\n",
    "\n",
    "    # Plotly files for all words (some missing)\n",
    "    # jsons = \"\"\n",
    "    # for word in wordlist:\n",
    "    #     word_ = re.sub(\" \", \"_\", word)\n",
    "    #     json = r'{{< load-plotly >}}' + '\\n' + r'{{< plotly json=\"/plotly/diffusion_name_' + word_ + r'.json\" height=\"300px\" >}}' + '\\n\\n'\n",
    "    #     jsons += json\n",
    "    # jsons = \"## Etymology maps\\n\\n\" + jsons\n",
    "    \n",
    "    # # Manuscripts (handwritten spice pages embedded into the generated one)\n",
    "    # for key in list_of_manuscripts:\n",
    "    # filename = re.sub(\" \", \"_\", key)\n",
    "    # with open(path + filename + \".md\", 'r', encoding=\"utf8\") as md:\n",
    "    #     lines = md.readlines()\n",
    "    #     text = \"\".join(lines)\n",
    "    # text = re.sub('\\n',' ',text)\n",
    "\n",
    "    # manuscript?? = '{{% include \"content/items/manuscripts/{' + key + '}_ms.md\" %}}\\n\\n' # not working\n",
    "\n",
    "    # Bibliography\n",
    "    bibliography = \"# Bibliography\\n\\n{{< bibliography cited >}}\\n\\n\"\n",
    "    \n",
    "    # Write markdown file\n",
    "    with open(path_out_md + key + '_bib.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(bibliography)\n",
    "\n",
    "    ######## Assemble page ########\n",
    "    page = preamble + display_gallery + page_description + quick_names + overview + intro + illustration + distribution + names + etymologies + gallery + references\n",
    "    \n",
    "    # Write markdown file\n",
    "    with open(path_out_md + key + '_gen.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(page)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Sichuan pepper\n",
      "Working on allspice\n",
      "Working on anise\n",
      "Working on asafoetida\n",
      "Working on caraway\n",
      "Working on cardamom\n",
      "Working on cassia\n",
      "Working on chile\n",
      "Working on cinnamon\n",
      "Working on clove\n",
      "Working on coriander\n",
      "Working on cumin\n",
      "Working on dill\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on fennel\n",
      "Working on fenugreek\n",
      "Working on ginger\n",
      "Working on long pepper\n",
      "Working on mace\n",
      "Working on nutmeg\n",
      "Working on pepper\n",
      "Working on saffron\n",
      "Working on star anise\n",
      "Working on turmeric\n",
      "Working on vanilla\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Loop through all spices\n",
    "for key in list_of_items:\n",
    "    spicepage(key)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge autogenerated files with manuscripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_page(key):\n",
    "    '''\n",
    "    This function merges generated web pages with hand written parts (manuscripts), and page bibliographies into a final markdown file to show on a web page. Gen and bib are generated above, manuscripts are not. E.g., allspice_gen.md + allspice_ms.md + allspice_bib.md = allspice.md.\n",
    "    '''\n",
    "    filename = re.sub(\" \", \"_\", key)\n",
    "    filepath = website_md + '/manuscripts/' + filename + '_ms.md'\n",
    "    if os.path.isfile(filepath) == True:\n",
    "        # Read generated files\n",
    "        with open(path_out_md + filename + '_gen.md', 'r', encoding='utf-8') as f:\n",
    "            generated = f.read()\n",
    "        # Read manuscript files    \n",
    "        with open(website_md + '/manuscripts/' + filename + '_ms.md', 'r', encoding='utf-8') as f:\n",
    "            manuscript = f.read()\n",
    "        # Read bib files\n",
    "        with open(path_out_md + filename + '_bib.md', 'r', encoding='utf-8') as f:\n",
    "            bibliography = f.read()\n",
    "        # Assemble    \n",
    "        page = generated + \"\\n\\n\" + manuscript + \"\\n\\n\" + bibliography\n",
    "        # Write out page file\n",
    "        with open(website_md + filename + '.md', 'w', encoding='utf-8') as f:\n",
    "            f.write(page)\n",
    "    else:\n",
    "        # Read generated files\n",
    "        with open(path_out_md + filename + '_gen.md', 'r', encoding='utf-8') as f:\n",
    "            generated = f.read()\n",
    "        # Read bib files    \n",
    "        with open(path_out_md + filename + '_bib.md', 'r', encoding='utf-8') as f:\n",
    "            bibliography = f.read()\n",
    "        # Assemble    \n",
    "        page = generated + \"\\n\\n\" + bibliography\n",
    "        # Write out page file\n",
    "        with open(website_md + filename + '.md', 'w', encoding='utf-8') as f:\n",
    "            f.write(page)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list_of_items:\n",
    "    build_page(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done at 2023-11-01 15:43:22.196978.\n",
      "Duration: 0:00:04.618657\n"
     ]
    }
   ],
   "source": [
    "# ...measure time\n",
    "end_time = datetime.now()\n",
    "print(\"All done at \" + str(end_time) + \".\")\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_items.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic example with Plotly Go\n",
    "# # Create figure data\n",
    "# fig = go.Figure(data=go.Scattergeo(\n",
    "#         lon = df['lon'],\n",
    "#         lat = df['lat'],\n",
    "#         text = df['item'],\n",
    "#         mode = 'markers',\n",
    "#         # marker_color = df['cnt'],\n",
    "#         ))\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(\n",
    "#         title = 'Title',\n",
    "#         geo_scope='world',\n",
    "#         template = 'plotly_dark'\n",
    "#     )\n",
    "\n",
    "# # Show figure\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual variables for map (dark mode)\n",
    "\n",
    "font_size = 14\n",
    "font_color = \"white\"\n",
    "font_family = \"Sans-Serif\"\n",
    "marker_symbol= 'circle'\n",
    "marker_size = 14\n",
    "max_marker_size = 32\n",
    "edge_color = transparent\n",
    "edge_size = 1\n",
    "opacity = 0.7\n",
    "line_width = 4\n",
    "water = \"#202020\"\n",
    "grid_color = \"#282828\"\n",
    "land = \"#303030\"\n",
    "lines = \"#383838\"\n",
    "copyright_color = \"#404040\"\n",
    "background_color = transparent\n",
    "legend_background_color = quarter_transparent\n",
    "color_scheme = prism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthographic globe layout\n",
    "ortho_traces = dict(\n",
    "    textposition = 'top right', # middle left, bottom center, etc.\n",
    "    textfont = dict(size=font_size, color=font_color, family=font_family),\n",
    "    hovertemplate=\n",
    "        \"<b>%{text}</b><br><br>\" +\n",
    "        \"Species: <i>%{customdata[0]}</i><br>\" +\n",
    "        \"Family: <i>%{customdata[1]}</i><br>\" +\n",
    "        \"Region of origin: %{customdata[2]}<br>\" +\n",
    "        \"Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>\" +\n",
    "        \"Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br>\" +\n",
    "        # \"Spreadability: %{customdata[7]:.2f}<br>\" +\n",
    "        \"<extra></extra>\",\n",
    "    marker = dict(\n",
    "        symbol = marker_symbol,\n",
    "        size = marker_size,\n",
    "        line = dict(\n",
    "            color=edge_color,\n",
    "            width=edge_size\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "ortho_layout = go.Layout(\n",
    "    paper_bgcolor=background_color,\n",
    "    plot_bgcolor=background_color,\n",
    "    geo = dict(\n",
    "        resolution=110, # 50 is large; 110 is small\n",
    "        scope='world', # 'world', 'asia'\n",
    "        projection_type = 'orthographic', # orthographic, natural earth\n",
    "        projection_scale = 1,\n",
    "        projection_rotation = {'lat': 20, 'lon': 80, 'roll': 0},\n",
    "        bgcolor=background_color,\n",
    "        showcoastlines=True, coastlinewidth = 1, coastlinecolor = lines,\n",
    "        showcountries=False, countrywidth = 1, countrycolor = lines,\n",
    "        showframe=True, framewidth = 1, framecolor = lines,\n",
    "        showlakes=True, lakecolor = water,\n",
    "        showland=True, landcolor = land,\n",
    "        showocean=True, oceancolor = water,\n",
    "        showrivers=True, riverwidth = 1, rivercolor = water,\n",
    "        showsubunits=True, subunitwidth = 0, subunitcolor = lines,\n",
    "        lonaxis = dict(showgrid = True, gridwidth = 0.5, dtick = 10, gridcolor=grid_color),\n",
    "        lataxis = dict (showgrid = True, gridwidth = 0.5, dtick = 10, gridcolor=grid_color)),\n",
    "    showlegend = True,\n",
    "    legend=dict(x=0, y=0, xanchor=\"left\", yanchor=\"bottom\", bgcolor=legend_background_color,\n",
    "                font=dict(color=font_color, size=font_size, family=font_family),\n",
    "                title_font=dict(color=font_color, size=font_size+2, family=font_family),\n",
    "                traceorder = 'normal', orientation=\"v\"),\n",
    "    title=dict(x=0.5, y=0.99, xanchor='center', yanchor='top', text='',\n",
    "               font=dict(color=font_color, size=font_size+6, family=font_family)),\n",
    "    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "    hoverlabel=dict(#bgcolor=\"white\",\n",
    "                    font_size=font_size,\n",
    "                    font_family=font_family),\n",
    "    )\n",
    "\n",
    "# \"Document size\" for pdfs\n",
    "document_size = dict(width = 600, height=600)\n",
    "\n",
    "# Copyright\n",
    "cr = dict(\n",
    "    name=\"copyright\",\n",
    "    text=\"© Gábor Parti, 2023\",\n",
    "    font=dict(color=copyright_color, size=8, family=font_family),\n",
    "    opacity=0.9,\n",
    "    xref=\"paper\",\n",
    "    yref=\"paper\",\n",
    "    x=0.5,\n",
    "    y=0,\n",
    "    # xanchor=\"right\", \n",
    "    # yanchor=\"bottom\", \n",
    "    # align=\"center\",\n",
    "    showarrow=False,\n",
    ")\n",
    "# fig.update_layout(annotations = [cr]) # to call\n",
    "\n",
    "## Info\n",
    "info = dict(\n",
    "    name=\"info\",\n",
    "    text=\"Click on a material to navigate to its corresponding page!\",\n",
    "    font=dict(color=font_color, size=font_size, family=font_family),\n",
    "    opacity=0.9,\n",
    "    xref=\"paper\",\n",
    "    yref=\"paper\",\n",
    "    x=0.5,\n",
    "    y=0.05,\n",
    "    # xanchor=\"right\", \n",
    "    # yanchor=\"bottom\", \n",
    "    # align=\"center\",\n",
    "    showarrow=False,\n",
    ")\n",
    "# fig.update_layout(annotations = [info]) # to call\n",
    "\n",
    "# Adding layout images\n",
    "logo = dict(\n",
    "    source=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9e/PolyU_Logo_with_wordmark.svg/1024px-PolyU_Logo_with_wordmark.svg.png\",\n",
    "    sizex=0.15, sizey=0.15,\n",
    "    x=1, y=0, \n",
    "    xanchor=\"right\", \n",
    "    yanchor=\"bottom\", \n",
    ")\n",
    "# fig.add_layout_image(logo) # to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural earth layout for cloropleth maps (regions and distributions)\n",
    "ne_traces = dict(\n",
    "    hovertemplate=\n",
    "        \"Region: <i>%{customdata[0]}</i><br>\" +\n",
    "        \"Code: <i>%{customdata[1]}</i><br>\" +\n",
    "        \"<extra></extra>\",\n",
    ")\n",
    "\n",
    "ne_layout = go.Layout(\n",
    "    paper_bgcolor=background_color,\n",
    "    plot_bgcolor=background_color,\n",
    "    geo = dict(\n",
    "        resolution=110, # 50 is large; 110 is small\n",
    "        scope='world', # 'world', 'asia'\n",
    "        projection_type = 'orthographic', #'natural earth',\n",
    "        projection_scale = 2,\n",
    "        projection_rotation = {'lat': 20, 'lon': 80, 'roll': 0},\n",
    "        bgcolor=background_color,\n",
    "        showcoastlines=True, coastlinewidth = 1, coastlinecolor = lines,\n",
    "        showcountries=False, countrywidth = 1, countrycolor = lines,\n",
    "        showframe=True, framewidth = 1, framecolor = lines,\n",
    "        showlakes=True, lakecolor = water,\n",
    "        showland=True, landcolor = land,\n",
    "        showocean=True, oceancolor = water,\n",
    "        showrivers=True, riverwidth = 1, rivercolor = water,\n",
    "        showsubunits=True, subunitwidth = 0, subunitcolor = lines,\n",
    "        lonaxis = dict(showgrid = True, gridwidth = 0.5, dtick = 10, gridcolor=grid_color),\n",
    "        lataxis = dict (showgrid = True, gridwidth = 0.5, dtick = 10, gridcolor=grid_color)),\n",
    "    showlegend = True,\n",
    "    legend=dict(xanchor=\"left\", yanchor=\"bottom\", \n",
    "                # x=0.1, y=0.1, # for natural earth\n",
    "                x=0, y=0, # for orthographic\n",
    "                bgcolor=legend_background_color,\n",
    "                font=dict(color=font_color, size=font_size, family=font_family),\n",
    "                title_font=dict(color=font_color, size=font_size+2, family=font_family),\n",
    "                traceorder = 'normal', orientation=\"v\"),\n",
    "    title=dict(x=0.5, y=0.99, xanchor='center', yanchor='top', text='',\n",
    "               font=dict(color=font_color, size=font_size+6, family=font_family)),\n",
    "    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "    hoverlabel=dict(#bgcolor=\"white\",\n",
    "                    font_size=font_size,\n",
    "                    font_family=font_family),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Pimenta dioica",
           "Myrtaceae",
           "S. Mexico to C. America; Caribbean",
           "فلفل إفرنجي",
           "fulful ifranjī",
           "多香果",
           "duōxiāngguǒ",
           -77,
           18,
           1
          ],
          [
           "Syzygium aromaticum",
           "Myrtaceae",
           "N. Moluccas, Indonesia",
           "قرنفل",
           "qaranful",
           "丁香",
           "dīngxiāng",
           127,
           0,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "allspice",
          "clove"
         ],
         "lat": [
          18,
          0
         ],
         "legendgroup": "Myrtaceae",
         "lon": [
          -77,
          127
         ],
         "marker": {
          "color": "#5f4690",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Myrtaceae",
         "showlegend": true,
         "text": [
          "allspice",
          "clove"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Pimpinella anisum",
           "Apiaceae",
           "E. Mediterranean; W. Asia; Asia Minor",
           "أنيسون",
           "anīsūn",
           "茴芹",
           "huíqín",
           35,
           39,
           1
          ],
          [
           "Ferula foetida",
           "Apiaceae",
           "Iran; W. and C. Asia",
           "حلتیت",
           "ḥiltīt",
           "阿魏",
           "āwèi",
           55,
           35,
           1
          ],
          [
           "Carum carvi",
           "Apiaceae",
           "Mediterranean; C. Europe; Eurasia",
           "كراويا",
           "karāwiyā",
           "葛縷子",
           "gě​lǚ​zi",
           69,
           45,
           1
          ],
          [
           "Coriandrum sativum",
           "Apiaceae",
           "E. Mediterranean; W. Asia",
           "كزبرة",
           "kuzbara",
           "芫荽",
           "yán​sui",
           45,
           40,
           1
          ],
          [
           "Cuminum cyminum",
           "Apiaceae",
           "S. Europe; W. & C. Asia; India",
           "كمون ",
           "kammūn",
           "孜然",
           "zī​rán",
           53,
           32,
           1
          ],
          [
           "Anethum graveolens",
           "Apiaceae",
           "S. Europe; N. Africa; SW. Asia",
           "شبت",
           "shibitt",
           "蒔蘿",
           "shíluó",
           30,
           28,
           1
          ],
          [
           "Foeniculum vulgare",
           "Apiaceae",
           "Mediterranean",
           "شمر",
           "shamar",
           "茴香",
           "huíxiāng",
           42,
           29,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "anise",
          "asafoetida",
          "caraway",
          "coriander",
          "cumin",
          "dill",
          "fennel"
         ],
         "lat": [
          39,
          35,
          45,
          40,
          32,
          28,
          29
         ],
         "legendgroup": "Apiaceae",
         "lon": [
          35,
          55,
          69,
          45,
          53,
          30,
          42
         ],
         "marker": {
          "color": "#1d6996",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Apiaceae",
         "showlegend": true,
         "text": [
          "anise",
          "asafoetida",
          "caraway",
          "coriander",
          "cumin",
          "dill",
          "fennel"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Elettaria cardamomum",
           "Zingiberaceae",
           "Kerala, S. India; southern Asia",
           "هال",
           "hāl",
           "豆蔻",
           "dòukòu",
           75,
           16,
           1
          ],
          [
           "Zingiber officinale",
           "Zingiberaceae",
           "South East Asia; India (secondary)",
           "زنجبيل",
           "zanjabīl",
           "薑",
           "jiāng",
           95,
           24,
           1
          ],
          [
           "Curcuma longa",
           "Zingiberaceae",
           "India",
           "كركم",
           "kurkum",
           "薑黃",
           "jiānghuáng",
           79,
           12,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "cardamom",
          "ginger",
          "turmeric"
         ],
         "lat": [
          16,
          24,
          12
         ],
         "legendgroup": "Zingiberaceae",
         "lon": [
          75,
          95,
          79
         ],
         "marker": {
          "color": "#38a6a5",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Zingiberaceae",
         "showlegend": true,
         "text": [
          "cardamom",
          "ginger",
          "turmeric"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Cinnamomum cassia",
           "Lauraceae",
           "Southeast China",
           "سليخة",
           "salīkha",
           "肉桂",
           "ròuguì",
           111,
           22,
           1
          ],
          [
           "Cinnamomum verum",
           "Lauraceae",
           "Sri Lanka; SW. India",
           "قرفة",
           "qirfa",
           "錫蘭肉桂",
           "xīlánròuguì",
           81,
           7,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "cassia",
          "cinnamon"
         ],
         "lat": [
          22,
          7
         ],
         "legendgroup": "Lauraceae",
         "lon": [
          111,
          81
         ],
         "marker": {
          "color": "#0f8554",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Lauraceae",
         "showlegend": true,
         "text": [
          "cassia",
          "cinnamon"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Capsicum annuum",
           "Solanaceae",
           "Central America",
           "فلفل حار",
           "fulful hārr",
           "辣椒",
           "làjiāo",
           -85,
           12,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "chile"
         ],
         "lat": [
          12
         ],
         "legendgroup": "Solanaceae",
         "lon": [
          -85
         ],
         "marker": {
          "color": "#73af48",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Solanaceae",
         "showlegend": true,
         "text": [
          "chile"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Trigonella foenum-graecum",
           "Fabaceae",
           "S. Europe; W. Asia",
           "حلبة",
           "ḥulba",
           "胡蘆巴",
           "húlúbā",
           67,
           33,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "fenugreek"
         ],
         "lat": [
          33
         ],
         "legendgroup": "Fabaceae",
         "lon": [
          67
         ],
         "marker": {
          "color": "#edae08",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Fabaceae",
         "showlegend": true,
         "text": [
          "fenugreek"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Piper longum",
           "Piperaceae",
           "E. Himalaya to S. China; Indo-China; India",
           "دارفلفل",
           "dārfilfil",
           "蓽撥",
           "bìbō",
           80,
           23,
           1
          ],
          [
           "Piper nigrum",
           "Piperaceae",
           "Malabar coast (South India)",
           "فلفل",
           "filfil, fulful",
           "胡椒",
           "hújiāo",
           76,
           14,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "long pepper",
          "pepper"
         ],
         "lat": [
          23,
          14
         ],
         "legendgroup": "Piperaceae",
         "lon": [
          80,
          76
         ],
         "marker": {
          "color": "#e17909",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Piperaceae",
         "showlegend": true,
         "text": [
          "long pepper",
          "pepper"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Myristica fragrans",
           "Myristicaceae",
           "Moluccas (Indonesia)",
           "بسباسة",
           "basbāsa",
           "肉豆蔻皮",
           "ròudòukòupí",
           130,
           -6,
           1
          ],
          [
           "Myristica fragrans",
           "Myristicaceae",
           "Moluccas (Indonesia)",
           "جوز الطيب",
           "jawz al-ṭīb",
           "肉豆蔻",
           "ròudòukòu",
           129,
           -4,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "mace",
          "nutmeg"
         ],
         "lat": [
          -6,
          -4
         ],
         "legendgroup": "Myristicaceae",
         "lon": [
          130,
          129
         ],
         "marker": {
          "color": "#cc503e",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Myristicaceae",
         "showlegend": true,
         "text": [
          "mace",
          "nutmeg"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Crocus sativus",
           "Iridaceae",
           "Greece; Near East",
           "زعفران",
           "zaʿfarān",
           "藏紅花",
           "zànghónghuā",
           25,
           36,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "saffron"
         ],
         "lat": [
          36
         ],
         "legendgroup": "Iridaceae",
         "lon": [
          25
         ],
         "marker": {
          "color": "#94346e",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Iridaceae",
         "showlegend": true,
         "text": [
          "saffron"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Zanthoxylum bungeanum",
           "Rutaceae",
           "China",
           "فلفل سيتشوان",
           "fulful sītshuwān",
           "花椒",
           "huā​jiāo",
           105,
           35,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "Sichuan pepper"
         ],
         "lat": [
          35
         ],
         "legendgroup": "Rutaceae",
         "lon": [
          105
         ],
         "marker": {
          "color": "#6f4070",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Rutaceae",
         "showlegend": true,
         "text": [
          "Sichuan pepper"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Illicium verum",
           "Schisandraceae",
           "SE. China; Vietnam",
           "يانسون نجمي",
           "yānsūn najmī",
           "八角",
           "bājiǎo",
           106,
           18,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "star anise"
         ],
         "lat": [
          18
         ],
         "legendgroup": "Schisandraceae",
         "lon": [
          106
         ],
         "marker": {
          "color": "#a28aba",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Schisandraceae",
         "showlegend": true,
         "text": [
          "star anise"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        },
        {
         "customdata": [
          [
           "Vanilla planifolia",
           "Orchidaceae",
           "Tropical America",
           "فانيليا",
           "fānīliyā",
           "香草",
           "xiāngcǎo",
           -55,
           -10,
           1
          ]
         ],
         "geo": "geo",
         "hovertemplate": "<b>%{text}</b><br><br>Species: <i>%{customdata[0]}</i><br>Family: <i>%{customdata[1]}</i><br>Region of origin: %{customdata[2]}<br>Arabic: %{customdata[3]} <i>%{customdata[4]}</i><br>Chinese: %{customdata[5]} <i>%{customdata[6]}</i><br><extra></extra>",
         "hovertext": [
          "vanilla"
         ],
         "lat": [
          -10
         ],
         "legendgroup": "Orchidaceae",
         "lon": [
          -55
         ],
         "marker": {
          "color": "#6baed6",
          "line": {
           "color": "rgba(0,0,0,0)",
           "width": 1
          },
          "opacity": 0.7,
          "size": 14,
          "sizemode": "area",
          "sizeref": 0.0009765625,
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "Orchidaceae",
         "showlegend": true,
         "text": [
          "vanilla"
         ],
         "textfont": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "textposition": "top right",
         "type": "scattergeo"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#404040",
           "family": "Sans-Serif",
           "size": 8
          },
          "name": "copyright",
          "opacity": 0.9,
          "showarrow": false,
          "text": "© Gábor Parti, 2023",
          "x": 0.5,
          "xref": "paper",
          "y": 0,
          "yref": "paper"
         }
        ],
        "geo": {
         "bgcolor": "rgba(0,0,0,0)",
         "center": {},
         "coastlinecolor": "#383838",
         "coastlinewidth": 1,
         "countrycolor": "#383838",
         "countrywidth": 1,
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "framecolor": "#383838",
         "framewidth": 1,
         "lakecolor": "#202020",
         "landcolor": "#303030",
         "lataxis": {
          "dtick": 10,
          "gridcolor": "#282828",
          "gridwidth": 0.5,
          "showgrid": true
         },
         "lonaxis": {
          "dtick": 10,
          "gridcolor": "#282828",
          "gridwidth": 0.5,
          "showgrid": true
         },
         "oceancolor": "#202020",
         "projection": {
          "rotation": {
           "lat": 20,
           "lon": 80,
           "roll": 0
          },
          "scale": 1,
          "type": "orthographic"
         },
         "resolution": 110,
         "rivercolor": "#202020",
         "riverwidth": 1,
         "scope": "world",
         "showcoastlines": true,
         "showcountries": false,
         "showframe": true,
         "showlakes": true,
         "showland": true,
         "showocean": true,
         "showrivers": true,
         "showsubunits": true,
         "subunitcolor": "#383838",
         "subunitwidth": 0
        },
        "hoverlabel": {
         "font": {
          "family": "Sans-Serif",
          "size": 14
         }
        },
        "legend": {
         "bgcolor": "rgba(0,0,0,0.25)",
         "font": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 14
         },
         "itemsizing": "constant",
         "orientation": "v",
         "title": {
          "font": {
           "color": "white",
           "family": "Sans-Serif",
           "size": 16
          },
          "text": "family"
         },
         "tracegroupgap": 0,
         "traceorder": "normal",
         "x": 0,
         "xanchor": "left",
         "y": 0,
         "yanchor": "bottom"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "paper_bgcolor": "rgba(0,0,0,0)",
        "plot_bgcolor": "rgba(0,0,0,0)",
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "white",
          "family": "Sans-Serif",
          "size": 20
         },
         "text": "",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.99,
         "yanchor": "top"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set size\n",
    "df['size'] = 1\n",
    "\n",
    "# Create figure data\n",
    "data = px.scatter_geo(df,\n",
    "    lat='lat', \n",
    "    lon='lon',\n",
    "    text='item',\n",
    "    color='family',\n",
    "    color_discrete_sequence=color_scheme,\n",
    "    size_max = max_marker_size,\n",
    "    size = 'size',\n",
    "    opacity = opacity,\n",
    "    hover_name='item',\n",
    "    hover_data={'species':True, 'family':True, 'region of origin':True, 'Arabic':True, 'ar transliteration':True, 'Chinese':True, 'pinyin':True, 'lon':False, 'lat':False, 'size':False}, #'spreadability':':.2f', \n",
    "    labels={\"group\": \"category\"}\n",
    "    )\n",
    "\n",
    "# Save figure data\n",
    "fig = data\n",
    "\n",
    "###################################################\n",
    "# Interactive visualization (HTML/JSON) for the web\n",
    "\n",
    "# Call the orthographic traces and layout settings from above\n",
    "fig.update_traces(ortho_traces)\n",
    "fig.update_layout(ortho_layout)\n",
    "# fig.update_layout(title_text = \"Title\")\n",
    "# fig.update_layout(basemap_visible=True)\n",
    "\n",
    "# Add copyrigth\n",
    "fig.update_layout(annotations=[cr])\n",
    "\n",
    "# Show figure\n",
    "fig.show()\n",
    "\n",
    "# Write interactive visualization (HTML/JSON) for the web\n",
    "filename = \"home\"\n",
    "# fig.write_html(path_out_html + filename + \".html\")\n",
    "fig.write_json(path_out_json + filename + \".json\", validate=True, pretty=True)\n",
    "\n",
    "###################################################\n",
    "# Image (PNG/PDF) for documents\n",
    "\n",
    "# Call figure data\n",
    "# fig = data\n",
    "\n",
    "# Call the orthographic traces and layout settings from above\n",
    "# fig.update_traces(ortho_traces)\n",
    "# fig.update_layout(ortho_layout)\n",
    "# fig.update_layout(geo=dict(projection_rotation = {'lat': 20, 'lon': 80, 'roll': 0}))\n",
    "# fig.update_layout(document_size)\n",
    "\n",
    "# Show figure\n",
    "# fig.show()\n",
    "\n",
    "# filename = \"home\"\n",
    "# fig.write_image(path_out_png + filename + \".png\", scale=3)\n",
    "# fig.write_image(filename + \".pdf\", engine=\"kaleido\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files to the website folder\n",
    "move_dir(path_out_json, website_json, \"*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic map to show some countries, not very good\n",
    "\n",
    "# import plotly.express as px\n",
    "# import geopandas as gpd\n",
    "\n",
    "# # Load the world map data\n",
    "# world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# # Filter the data to include only India, Sri Lanka, and Maldives\n",
    "# target_countries = ['India', 'Sri Lanka', 'Maldives', 'Wales']\n",
    "# filtered_world = world[world['name'].isin(target_countries)]\n",
    "\n",
    "# # Create a choropleth map\n",
    "# fig = px.choropleth(\n",
    "#     filtered_world,\n",
    "#     locations='iso_a3',\n",
    "#     color='name',\n",
    "#     color_discrete_sequence = color_scheme,\n",
    "#     projection='orthographic',\n",
    "#     title='Highlighted Countries: India, Sri Lanka, Maldives'\n",
    "# )\n",
    "\n",
    "# # Call the orthographic traces and layout settings from above\n",
    "# fig.update_layout(ortho_layout)\n",
    "# # fig.update_layout(title_text = \"Title\")\n",
    "\n",
    "# # Show the map\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_items.copy()\n",
    "\n",
    "key = \"saffron\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Habitat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def habitat_map(key):\n",
    "    '''\n",
    "    This function generates a map of the distributions of a spice.\n",
    "    '''\n",
    "\n",
    "    # Load the geographic data (shapefile or GeoJSON) # https://github.com/tdwg/wgsrpd\n",
    "    gdf = gpd.read_file(\"data\\\\resources\\\\geo\\\\level3.geojson\")\n",
    "\n",
    "    # Rename columns\n",
    "    gdf.columns = ['name', 'code', 'code_l2', 'code_l1', 'geometry']\n",
    "\n",
    "    # Get local df and reset its index\n",
    "    df_local = df_items.loc[df_items['item'] == key]\n",
    "    df_local.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Get list of native regions\n",
    "    native_regions = df_local.loc[0, 'native regions'].split(', ')\n",
    "\n",
    "    # Get list of introduced regions, if it is not NA\n",
    "    if pd.notna(df_local.loc[0, 'introduced regions']):\n",
    "        introduced_regions = df_local.loc[0, 'introduced regions'].split(', ')\n",
    "    else:\n",
    "        introduced_regions = []\n",
    "\n",
    "    # Filter data for native regions from gdf dataframe's LEVEL3_NAM column\n",
    "    filtered_data_native = gdf[gdf['name'].isin(native_regions)].copy()  # Ensure a copy is made\n",
    "    filtered_data_native.loc[:, 'region'] = 'native'\n",
    "\n",
    "    # Filter data for introduced regions from gdf dataframe's LEVEL3_NAM column\n",
    "    filtered_data_introduced = gdf[gdf['name'].isin(introduced_regions)].copy()  # Ensure a copy is made\n",
    "    if not filtered_data_introduced.empty:\n",
    "        filtered_data_introduced.loc[:, 'region'] = 'introduced'\n",
    "\n",
    "    # Concatenate the filtered dataframes\n",
    "    filtered_data = pd.concat([filtered_data_native, filtered_data_introduced])\n",
    "\n",
    "    # ***\n",
    "\n",
    "    # Create the choropleth map\n",
    "    fig = px.choropleth(\n",
    "        filtered_data,\n",
    "        geojson = filtered_data.geometry,\n",
    "        locations = filtered_data.index,\n",
    "        color = 'region',\n",
    "        color_discrete_sequence = ['#88ae43', '#6943ae'],\n",
    "        hover_data = {'name': True, 'code': True},\n",
    "        projection = 'natural earth'\n",
    "    )\n",
    "\n",
    "    # Call layout\n",
    "    fig.update_traces(ne_traces)\n",
    "    fig.update_layout(ne_layout)\n",
    "\n",
    "    # Adjust map bounds\n",
    "    # fig.update_geos(fitbounds='locations')  \n",
    "\n",
    "    # Get centroid values for the native regions of the item\n",
    "    for index, row in df_local.iterrows():\n",
    "        native_distribution = row['native regions'].split(', ')\n",
    "        # Filter data for native distribution from gdf dataframe's LEVEL3_NAM column\n",
    "        native_data = gdf[gdf['name'].isin(native_distribution)].copy() \n",
    "        # Calculate centroid data\n",
    "        native_centroid = native_data.centroid\n",
    "        native_centroid_lon = native_centroid.x.iloc[0]\n",
    "        native_centroid_lat = native_centroid.y.iloc[0]\n",
    "\n",
    "    # Amend projection rotation with the native regions' centroid values\n",
    "    fig.update_layout(geo=dict(projection_rotation = {'lat': native_centroid_lat, 'lon': native_centroid_lon, 'roll': 0}))\n",
    "\n",
    "    # Show the map\n",
    "    # fig.show()\n",
    "\n",
    "    # Save\n",
    "    filename = \"dist_\" + re.sub(\" \", \"_\", key).lower()\n",
    "    # fig.write_html(path_out_html + filename + \".html\")\n",
    "    fig.write_json(path_out_json + filename + \".json\", validate=True, pretty=True)\n",
    "    # fig.write_image(path_out_png + filename + \".png\", scale=3)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through all spices\n",
    "# for key in list_of_items:\n",
    "#     print(key)\n",
    "#     habitat_map(key)\n",
    "# print(\"Done.\")\n",
    "\n",
    "# # Move files to the website folder\n",
    "# move_dir(path_out_json, website_json + \"/distributions\", \"*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gpd.datasets.available)\n",
    "# import geodatasets\n",
    "# geodatasets.data\n",
    "\n",
    "# with open(\"data\\\\resources\\\\geo\\\\level3.geojson\", 'r') as f:\n",
    "#     geojson_data = json.load(f)\n",
    "\n",
    "# geojson_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
